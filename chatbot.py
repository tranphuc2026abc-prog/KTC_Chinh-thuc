import os
import glob
import streamlit as st
import shutil
import re
import uuid
import unicodedata 
from pathlib import Path
from typing import List, Optional

# --- Imports (Giá»¯ nguyÃªn thÆ° viá»‡n nhÆ° yÃªu cáº§u) ---
try:
    import nest_asyncio
    nest_asyncio.apply() 
    from llama_parse import LlamaParse 
    
    from langchain_text_splitters import RecursiveCharacterTextSplitter
    from langchain_community.vectorstores import FAISS
    from langchain_community.retrievers import BM25Retriever
    from langchain.retrievers import EnsembleRetriever
    from langchain_huggingface import HuggingFaceEmbeddings
    from langchain_core.documents import Document
    from groq import Groq
    # Rerank optimization
    from flashrank import Ranker, RerankRequest
    DEPENDENCIES_OK = True
except ImportError as e:
    DEPENDENCIES_OK = False
    IMPORT_ERROR = str(e)

# =============================
# 1. Cáº¤U HÃŒNH Há»† THá»NG (CONFIG) 
# =============================

st.set_page_config(
    page_title="KTC Chatbot - THCS & THPT Pháº¡m Kiá»‡t",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

class AppConfig:
    # --- Cáº¥u hÃ¬nh API & Model ---
    GROQ_API_KEY = "gsk_..." # ÄIá»€N API KEY Cá»¦A THáº¦Y VÃ€O ÄÃ‚Y HOáº¶C DÃ™NG ST.SECRETS
    LLM_MODEL = "llama-3.3-70b-versatile" 
    EMBEDDING_MODEL = "dangvantuan/vietnamese-embedding"
    
    # --- Cáº¥u hÃ¬nh thÆ° má»¥c ---
    UPLOAD_DIR = "PDF_KNOWLEDGE"
    VECTOR_DB_DIR = "FAISS_DB"
    LOGO_PROJECT = "LOGO.jpg"
    
    # --- Prompt Engineering (Giá»¯ nguyÃªn) ---
    SYSTEM_PROMPT = """Báº¡n lÃ  Trá»£ lÃ½ há»c táº­p mÃ´n Tin há»c, há»— trá»£ há»c sinh dá»±a trÃªn SGK Káº¿t ná»‘i tri thá»©c (KNTT).
    
    QUY Táº®C TRáº¢ Lá»œI:
    1.  CHá»ˆ sá»­ dá»¥ng thÃ´ng tin tá»« ngá»¯ cáº£nh (Context) Ä‘Æ°á»£c cung cáº¥p bÃªn dÆ°á»›i.
    2.  Náº¿u khÃ´ng tÃ¬m tháº¥y thÃ´ng tin trong Context, hÃ£y nÃ³i rÃµ: "Dá»±a trÃªn tÃ i liá»‡u SGK hiá»‡n cÃ³, tÃ´i chÆ°a tÃ¬m tháº¥y thÃ´ng tin nÃ y."
    3.  TrÃ­ch dáº«n nguá»“n chÃ­nh xÃ¡c: (TÃªn sÃ¡ch - Chá»§ Ä‘á» - BÃ i).
    4.  Giá»ng vÄƒn: SÆ° pháº¡m, khÃ­ch lá»‡, dá»… hiá»ƒu, phÃ¹ há»£p há»c sinh.
    
    Cáº¤U TRÃšC TRáº¢ Lá»œI:
    - **Lá»i giáº£i Ä‘Ã¡p:** [Ná»™i dung chi tiáº¿t]
    - **Nguá»“n tham kháº£o:** [Tá»± Ä‘á»™ng trÃ­ch xuáº¥t tá»« metadata]
    """

# ========================================================
# 2. Xá»¬ LÃ Dá»® LIá»†U Äáº¶C THÃ™ CHO SGK KNTT (CORE RAG LOGIC)
# ========================================================

class KNTT_TextProcessor:
    """
    Class chuyÃªn biá»‡t Ä‘á»ƒ xá»­ lÃ½ cáº¥u trÃºc: TÃªn sÃ¡ch -> Chá»§ Ä‘á» -> BÃ i
    DÃ nh cho dá»± thi KHKT - Tá»‘i Æ°u hÃ³a viá»‡c truy xuáº¥t nguá»“n.
    """
    
    @staticmethod
    def normalize_text(text: str) -> str:
        """LÃ m sáº¡ch vÄƒn báº£n cÆ¡ báº£n."""
        if not text: return ""
        text = unicodedata.normalize("NFC", text)
        return re.sub(r'\s+', ' ', text).strip()

    @staticmethod
    def parse_structure(text: str, filename: str) -> List[Document]:
        """
        PhÃ¢n tÃ­ch cÃº phÃ¡p vÄƒn báº£n theo cáº¥u trÃºc: Chá»§ Ä‘á» -> BÃ i.
        Chá»‰ giá»¯ láº¡i ná»™i dung thuá»™c (Chá»§ Ä‘á» AND BÃ i).
        """
        lines = text.split('\n')
        structured_docs = []
        
        # Regex báº¯t "Chá»§ Ä‘á»" (VÃ­ dá»¥: Chá»§ Ä‘á» 1, Chá»§ Ä‘á» E...)
        # Báº¯t cÃ¡c biáº¿n thá»ƒ: "Chá»§ Ä‘á» 1", "CHá»¦ Äá»€ 1", "Chá»§ Ä‘á» A:"
        topic_pattern = re.compile(r'^(?:Chá»§ Ä‘á»|CHá»¦ Äá»€)\s+([0-9A-Za-z]+)(?:[:\.]|\s+)(.+)$', re.IGNORECASE)
        
        # Regex báº¯t "BÃ i" (VÃ­ dá»¥: BÃ i 1, BÃ i 5...)
        lesson_pattern = re.compile(r'^(?:BÃ i|BÃ€I)\s+([0-9]+)(?:[:\.]|\s+)(.+)$', re.IGNORECASE)

        current_topic_id = None
        current_topic_title = None
        current_lesson_id = None
        current_lesson_title = None
        
        current_buffer = []
        
        # TÃªn sÃ¡ch chuáº©n hÃ³a (Bá» Ä‘uÃ´i .pdf)
        source_name = os.path.splitext(filename)[0]

        def commit_chunk():
            """LÆ°u Ä‘oáº¡n vÄƒn báº£n hiá»‡n táº¡i náº¿u Ä‘á»§ Ä‘iá»u kiá»‡n (CÃ³ Topic AND Lesson)."""
            nonlocal current_buffer
            content = "\n".join(current_buffer).strip()
            
            # ÄIá»€U KIá»†N Sá»NG CÃ’N: Pháº£i cÃ³ cáº£ Chá»§ Ä‘á» vÃ  BÃ i má»›i lÆ°u
            if content and current_topic_id and current_lesson_id:
                # Táº¡o Topic Ä‘áº§y Ä‘á»§: "Chá»§ Ä‘á» 1. MÃ¡y tÃ­nh..."
                full_topic = f"Chá»§ Ä‘á» {current_topic_id}: {current_topic_title}"
                # Táº¡o Lesson Ä‘áº§y Ä‘á»§: "BÃ i 5. Dá»¯ liá»‡u..."
                full_lesson = f"BÃ i {current_lesson_id}: {current_lesson_title}"
                
                doc = Document(
                    page_content=content,
                    metadata={
                        "source": source_name,
                        "topic": full_topic,
                        "lesson": full_lesson,
                        "chunk_uid": str(uuid.uuid4())
                    }
                )
                structured_docs.append(doc)
            
            # Reset buffer sau khi commit (hoáº·c bá» qua)
            current_buffer = []

        for line in lines:
            line_clean = KNTT_TextProcessor.normalize_text(line)
            if not line_clean:
                continue

            # 1. Kiá»ƒm tra xem dÃ²ng nÃ y cÃ³ pháº£i lÃ  CHá»¦ Äá»€ má»›i khÃ´ng?
            topic_match = topic_pattern.match(line_clean)
            if topic_match:
                commit_chunk() # LÆ°u ná»™i dung bÃ i cÅ© trÆ°á»›c khi sang chá»§ Ä‘á» má»›i
                current_topic_id = topic_match.group(1).strip()
                current_topic_title = topic_match.group(2).strip()
                current_lesson_id = None # Sang chá»§ Ä‘á» má»›i thÃ¬ reset bÃ i
                current_lesson_title = None
                continue # DÃ²ng tiÃªu Ä‘á» khÃ´ng Ä‘Æ°a vÃ o ná»™i dung body

            # 2. Kiá»ƒm tra xem dÃ²ng nÃ y cÃ³ pháº£i lÃ  BÃ€I má»›i khÃ´ng?
            lesson_match = lesson_pattern.match(line_clean)
            if lesson_match:
                commit_chunk() # LÆ°u ná»™i dung pháº§n trÆ°á»›c
                current_lesson_id = lesson_match.group(1).strip()
                current_lesson_title = lesson_match.group(2).strip()
                continue

            # 3. Ná»™i dung thÆ°á»ng
            # Chá»‰ thu tháº­p náº¿u ÄÃƒ xÃ¡c Ä‘á»‹nh Ä‘Æ°á»£c Ä‘ang á»Ÿ trong Chá»§ Ä‘á» nÃ o vÃ  BÃ i nÃ o
            if current_topic_id and current_lesson_id:
                current_buffer.append(line_clean)

        # Commit pháº§n cuá»‘i cÃ¹ng
        commit_chunk()
        
        return structured_docs

class VectorStoreManager:
    def __init__(self):
        self.embeddings = HuggingFaceEmbeddings(model_name=AppConfig.EMBEDDING_MODEL)
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200,
            separators=["\n\n", "\n", ". ", " ", ""]
        )

    def build_db(self, uploaded_files):
        """Quy trÃ¬nh: LlamaParse -> Cáº¥u trÃºc hÃ³a KNTT -> Split -> Vector DB"""
        
        if not os.path.exists(AppConfig.UPLOAD_DIR):
            os.makedirs(AppConfig.UPLOAD_DIR)

        all_processed_docs = []
        status_text = st.empty()

        for uploaded_file in uploaded_files:
            file_path = os.path.join(AppConfig.UPLOAD_DIR, uploaded_file.name)
            with open(file_path, "wb") as f:
                f.write(uploaded_file.getbuffer())
            
            status_text.text(f"â³ Äang xá»­ lÃ½ cáº¥u trÃºc SGK: {uploaded_file.name}...")
            
            # 1. Parse PDF sang Markdown/Text báº±ng LlamaParse
            # (Giáº£ Ä‘á»‹nh API Key LlamaParse Ä‘Ã£ Ä‘Æ°á»£c set trong mÃ´i trÆ°á»ng hoáº·c code)
            parser = LlamaParse(result_type="text", language="vi")
            parsed_result = parser.load_data(file_path)
            
            if not parsed_result:
                continue
                
            raw_text = parsed_result[0].text
            
            # 2. Ká»¸ THUáº¬T QUAN TRá»ŒNG: Cáº¥u trÃºc hÃ³a dá»¯ liá»‡u theo chuáº©n KNTT
            # BÆ°á»›c nÃ y lá»c bá» rÃ¡c vÃ  gáº¯n tháº» Topic/Lesson
            structured_docs = KNTT_TextProcessor.parse_structure(raw_text, uploaded_file.name)
            
            # 3. Chia nhá» chunk (nhÆ°ng váº«n giá»¯ metadata Ä‘Ã£ gáº¯n)
            # DÃ¹ng split_documents Ä‘á»ƒ báº£o toÃ n metadata source/topic/lesson
            chunks = self.text_splitter.split_documents(structured_docs)
            all_processed_docs.extend(chunks)

        if not all_processed_docs:
            st.error("âŒ KhÃ´ng tÃ¬m tháº¥y ná»™i dung há»£p lá»‡ (Chá»§ Ä‘á» -> BÃ i) trong tÃ i liá»‡u!")
            return None

        # 4. Táº¡o Vector DB
        status_text.text(f"ğŸ§  Äang mÃ£ hÃ³a {len(all_processed_docs)} Ä‘oáº¡n tri thá»©c...")
        vector_db = FAISS.from_documents(all_processed_docs, self.embeddings)
        vector_db.save_local(AppConfig.VECTOR_DB_DIR)
        
        # LÆ°u cache BM25 (cho Hybrid Search)
        with open(f"{AppConfig.VECTOR_DB_DIR}/bm25_docs.pkl", "wb") as f:
            import pickle
            pickle.dump(all_processed_docs, f)
            
        status_text.empty()
        return vector_db

    def load_db(self):
        if os.path.exists(AppConfig.VECTOR_DB_DIR):
            return FAISS.load_local(
                AppConfig.VECTOR_DB_DIR, 
                self.embeddings, 
                allow_dangerous_deserialization=True
            )
        return None

# ==================================
# 3. RAG ENGINE (Hybrid + Rerank)
# ==================================

class RAGEngine:
    @staticmethod
    def get_retriever(vector_db):
        # 1. Vector Retriever
        faiss_retriever = vector_db.as_retriever(search_kwargs={"k": 5})
        
        # 2. BM25 Retriever (Keyword)
        try:
            with open(f"{AppConfig.VECTOR_DB_DIR}/bm25_docs.pkl", "rb") as f:
                import pickle
                docs = pickle.load(f)
            bm25_retriever = BM25Retriever.from_documents(docs)
            bm25_retriever.k = 5
            
            # 3. Hybrid Ensemble
            ensemble_retriever = EnsembleRetriever(
                retrievers=[bm25_retriever, faiss_retriever],
                weights=[0.4, 0.6]
            )
            return ensemble_retriever
        except:
            return faiss_retriever

    @staticmethod
    def generate_response(client, retriever, query):
        # A. Retrieve
        docs = retriever.invoke(query)
        
        # B. Rerank (Tá»‘i Æ°u hÃ³a thá»© háº¡ng)
        # Náº¿u tháº§y Khanh chÆ°a cÃ i flashrank hoáº·c muá»‘n táº¯t thÃ¬ comment Ä‘oáº¡n nÃ y
        try:
            ranker = Ranker(model_name="ms-marco-MiniLM-L-12-v2", cache_dir="./opt")
            rerank_request = RerankRequest(query=query, passages=[
                {"id": d.metadata.get("chunk_uid", "0"), "text": d.page_content, "meta": d.metadata} 
                for d in docs
            ])
            results = ranker.rank(rerank_request)
            # Láº¥y top 3 sau rerank
            top_docs = results[:3]
            context_text = ""
            sources_set = set()
            
            for r in top_docs:
                meta = r['meta']
                # Táº¡o chuá»—i nguá»“n chuáº©n: Tin 10 - Chá»§ Ä‘á» 1 - BÃ i 5
                src_str = f"{meta.get('source')} -> {meta.get('topic')} -> {meta.get('lesson')}"
                sources_set.add(src_str)
                context_text += f"\n---\nNá»™i dung: {r['text']}\nNguá»“n: {src_str}\n"
                
        except Exception as e:
            # Fallback náº¿u Rerank lá»—i
            top_docs = docs[:3]
            context_text = ""
            sources_set = set()
            for d in top_docs:
                meta = d.metadata
                src_str = f"{meta.get('source', 'Unknown')} -> {meta.get('topic', 'Unknown')} -> {meta.get('lesson', 'Unknown')}"
                sources_set.add(src_str)
                context_text += f"\n---\nNá»™i dung: {d.page_content}\nNguá»“n: {src_str}\n"

        # C. Generate
        full_prompt = f"""{AppConfig.SYSTEM_PROMPT}
        
        CÃ‚U Há»I Cá»¦A Há»ŒC SINH: {query}
        
        Dá»® LIá»†U SGK THAM KHáº¢O (ÄÃƒ ÄÆ¯á»¢C Lá»ŒC):
        {context_text}
        
        HÃƒY TRáº¢ Lá»œI:"""

        chat_completion = client.chat.completions.create(
            messages=[{"role": "user", "content": full_prompt}],
            model=AppConfig.LLM_MODEL,
            stream=True,
        )

        for chunk in chat_completion:
            if chunk.choices[0].delta.content:
                yield chunk.choices[0].delta.content
        
        # Hiá»ƒn thá»‹ nguá»“n cuá»‘i cÃ¢u tráº£ lá»i (Optional - hoáº·c Ä‘á»ƒ LLM tá»± nÃ³i)
        yield "\n\n**ğŸ“š Nguá»“n SGK:**\n" + "\n".join([f"- {s}" for s in sources_set])

# =======================
# 4. GIAO DIá»†N STREAMLIT
# =======================

def main():
    if not DEPENDENCIES_OK:
        st.error(f"âŒ Thiáº¿u thÆ° viá»‡n: {IMPORT_ERROR}. Vui lÃ²ng cháº¡y: pip install -r requirements.txt")
        return

    # Sidebar quáº£n lÃ½ dá»¯ liá»‡u
    with st.sidebar:
        st.image(AppConfig.LOGO_PROJECT if os.path.exists(AppConfig.LOGO_PROJECT) else "https://via.placeholder.com/150", width=100)
        st.title("ğŸ—‚ï¸ KHO TRI THá»¨C KNTT")
        
        uploaded_files = st.file_uploader(
            "Náº¡p SGK (PDF)", 
            type=["pdf"], 
            accept_multiple_files=True
        )
        
        if st.button("ğŸ”„ Cáº­p nháº­t Tri thá»©c (Build RAG)"):
            if uploaded_files:
                manager = VectorStoreManager()
                with st.spinner("Äang xÃ¢y dá»±ng láº¡i nÃ£o bá»™ AI..."):
                    db = manager.build_db(uploaded_files)
                    if db:
                        st.success("âœ… ÄÃ£ há»c xong SGK má»›i!")
                        st.session_state.vector_db = db
                        st.rerun()
            else:
                st.warning("âš ï¸ Vui lÃ²ng chá»n file PDF SGK!")

        st.markdown("---")
        st.markdown("**HÆ°á»›ng dáº«n:**\nUpload file PDF SGK cÃ³ tÃªn chuáº©n (VD: Tin 10_KNTT.pdf). Há»‡ thá»‘ng tá»± Ä‘á»™ng lá»c theo Chá»§ Ä‘á»/BÃ i.")

    # Main Chat Interface
    st.title("ğŸ¤– TRá»¢ LÃ Há»ŒC Táº¬P TIN Há»ŒC (RAG SYSTEM)")
    
    # Khá»Ÿi táº¡o session
    if "messages" not in st.session_state:
        st.session_state.messages = []
    
    if "retriever_engine" not in st.session_state:
        manager = VectorStoreManager()
        db = manager.load_db()
        if db:
            st.session_state.retriever_engine = RAGEngine.get_retriever(db)
        else:
            st.info("ğŸ‘‹ Xin chÃ o! HÃ£y náº¡p tÃ i liá»‡u SGK á»Ÿ cá»™t bÃªn trÃ¡i Ä‘á»ƒ báº¯t Ä‘áº§u.")

    # Hiá»ƒn thá»‹ lá»‹ch sá»­ chat
    for msg in st.session_state.messages:
        avatar = "ğŸ§‘â€ğŸ“" if msg["role"] == "user" else "ğŸ¤–"
        with st.chat_message(msg["role"], avatar=avatar):
            st.markdown(msg["content"])

    # Xá»­ lÃ½ input
    if user_input := st.chat_input("Nháº­p cÃ¢u há»i bÃ i há»c (VÃ­ dá»¥: TrÃ­ tuá»‡ nhÃ¢n táº¡o lÃ  gÃ¬ trong bÃ i 17?)"):
        st.session_state.messages.append({"role": "user", "content": user_input})
        with st.chat_message("user", avatar="ğŸ§‘â€ğŸ“"):
            st.markdown(user_input)

        with st.chat_message("assistant", avatar="ğŸ¤–"):
            if "retriever_engine" not in st.session_state:
                st.warning("âš ï¸ ChÆ°a cÃ³ dá»¯ liá»‡u SGK! Vui lÃ²ng náº¡p file bÃªn trÃ¡i.")
            else:
                try:
                    # Init Groq Client (ThÃªm API Key vÃ o Ä‘Ã¢y hoáº·c Secrets)
                    groq_client = Groq(api_key=AppConfig.GROQ_API_KEY)
                    
                    response_placeholder = st.empty()
                    full_response = ""
                    
                    # Gá»i hÃ m Generate
                    response_gen = RAGEngine.generate_response(
                        groq_client, 
                        st.session_state.retriever_engine, 
                        user_input
                    )
                    
                    for chunk in response_gen:
                        full_response += chunk
                        response_placeholder.markdown(full_response + "â–Œ")
                    
                    response_placeholder.markdown(full_response)
                    
                    st.session_state.messages.append({"role": "assistant", "content": full_response})
                    
                except Exception as e:
                    st.error(f"Lá»—i há»‡ thá»‘ng: {str(e)}")

if __name__ == "__main__":
    main()