import os
import glob
import time
import streamlit as st
from pathlib import Path

# --- Imports v·ªõi x·ª≠ l√Ω l·ªói th√¥ng minh ---
try:
    from pypdf import PdfReader
    from langchain_text_splitters import RecursiveCharacterTextSplitter
    from langchain_community.vectorstores import FAISS
    from langchain_huggingface import HuggingFaceEmbeddings
    from langchain_core.documents import Document
    from groq import Groq
    DEPENDENCIES_OK = True
except ImportError as e:
    DEPENDENCIES_OK = False
    IMPORT_ERROR = str(e)

# ==============================================================================
# 1. C·∫§U H√åNH H·ªÜ TH·ªêNG (CONFIG)
# ==============================================================================

st.set_page_config(
    page_title="KTC Chatbot - THCS & THPT Ph·∫°m Ki·ªát",
    page_icon="LOGO.jpg", # D√πng logo d·ª± √°n l√†m icon tab
    layout="wide",
    initial_sidebar_state="expanded"
)

class AppConfig:
    """C·∫•u h√¨nh trung t√¢m"""
    # Thay ƒë·ªïi model ·ªü ƒë√¢y n·∫øu c·∫ßn
    LLM_MODEL = 'llama-3.1-8b-instant'
    EMBEDDING_MODEL = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
    
    # ƒê∆∞·ªùng d·∫´n files
    PDF_DIR = "PDF_KNOWLEDGE"
    VECTOR_DB_PATH = "faiss_db_index"
    LOGO_PROJECT = "LOGO.jpg"     # Logo KTC
    LOGO_SCHOOL = "LOGO PKS.png"  # Logo Tr∆∞·ªùng Ph·∫°m Ki·ªát
    
    # Tham s·ªë RAG
    CHUNK_SIZE = 1000 
    CHUNK_OVERLAP = 200
    TOP_K_RETRIEVAL = 4
    MAX_CONTEXT_LENGTH = 3500

# ==============================================================================
# 2. UI/UX: GIAO DI·ªÜN HI-TECH (CUSTOM CSS)
# ==============================================================================

def inject_custom_css():
    st.markdown("""
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;700&display=swap');
        
        /* --- T·ªîNG TH·ªÇ --- */
        html, body, [class*="css"] {
            font-family: 'Roboto', sans-serif;
        }
        
        /* M√†u ch·ªß ƒë·∫°o theo Logo KTC: Xanh Cyan (#00E5FF) v√† Xanh ƒë·∫≠m */
        
        /* --- HEADER --- */
        .main-header {
            background: linear-gradient(135deg, #0f2027 0%, #203a43 50%, #2c5364 100%);
            padding: 1.5rem;
            border-radius: 15px;
            color: white;
            display: flex;
            align-items: center;
            justify-content: space-between;
            margin-bottom: 2rem;
            box-shadow: 0 4px 15px rgba(0, 229, 255, 0.2); /* ƒê·ªï b√≥ng xanh neon */
            border: 1px solid rgba(255,255,255,0.1);
        }
        
        .header-title h1 {
            color: #00E5FF !important; /* M√†u Cyan c·ªßa logo KTC */
            font-weight: 800;
            margin: 0;
            font-size: 2.2rem;
            text-shadow: 0 0 10px rgba(0, 229, 255, 0.5);
        }
        
        .header-title p {
            margin: 5px 0 0 0;
            font-size: 1rem;
            color: #e0e0e0;
        }

        /* --- SIDEBAR --- */
        [data-testid="stSidebar"] {
            background-color: #f8f9fa;
            border-right: 1px solid #ddd;
        }
        
        .project-card {
            background: white;
            padding: 15px;
            border-radius: 12px;
            box-shadow: 0 2px 8px rgba(0,0,0,0.05);
            margin-bottom: 20px;
            text-align: center;
            border: 1px solid #eee;
        }
        
        .author-info {
            font-size: 0.9rem;
            color: #333;
            margin-top: 10px;
            text-align: left;
        }
        
        .school-logo-container {
            margin-top: 20px;
            text-align: center;
            opacity: 0.9;
        }

        /* --- CHAT AREA --- */
        .stChatMessage {
            background-color: transparent;
        }
        
        /* User message: M√†u xanh nh·∫°t d·ªÖ ch·ªãu */
        [data-testid="stChatMessageContent"]:has(+ [data-testid="stChatMessageAvatar"]) {
            background: linear-gradient(to right, #e3f2fd, #bbdefb);
            border-radius: 20px 20px 5px 20px;
            color: #0d47a1;
            border: none;
            box-shadow: 0 1px 2px rgba(0,0,0,0.1);
        }
        
        /* AI message: M√†u tr·∫Øng s·∫°ch s·∫Ω, vi·ªÅn xanh neon nh·∫π */
        [data-testid="stChatMessageContent"]:not(:has(+ [data-testid="stChatMessageAvatar"])) {
            background-color: white;
            border: 1px solid #e1f5fe;
            border-left: 4px solid #00E5FF; /* ƒêi·ªÉm nh·∫•n KTC */
            border-radius: 5px 20px 20px 20px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.05);
        }

        /* --- SUGGESTION BUTTONS --- */
        div.stButton > button {
            border-radius: 20px;
            border: 1px solid #b3e5fc;
            background-color: white;
            color: #0277bd;
            font-size: 0.9rem;
            transition: all 0.3s;
        }
        div.stButton > button:hover {
            border-color: #00E5FF;
            color: #00E5FF;
            background-color: #e0f7fa;
            transform: translateY(-2px);
        }

        /* ·∫®n b·ªõt footer m·∫∑c ƒë·ªãnh */
        #MainMenu {visibility: hidden;}
        footer {visibility: hidden;}
        
    </style>
    """, unsafe_allow_html=True)

# ==============================================================================
# 3. LOGIC BACKEND (ƒê√É T·ªêI ∆ØU CACHING)
# ==============================================================================

@st.cache_resource(show_spinner=False)
def load_groq_client():
    try:
        # ∆Øu ti√™n l·∫•y t·ª´ secrets, n·∫øu kh√¥ng c√≥ th√¨ th·ª≠ bi·∫øn m√¥i tr∆∞·ªùng
        api_key = st.secrets.get("GROQ_API_KEY") or os.environ.get("GROQ_API_KEY")
        if not api_key: return None
        return Groq(api_key=api_key)
    except Exception: return None

@st.cache_resource(show_spinner=False)
def load_embedding_model():
    """Load model 1 l·∫ßn duy nh·∫•t khi kh·ªüi ƒë·ªông app"""
    try:
        return HuggingFaceEmbeddings(
            model_name=AppConfig.EMBEDDING_MODEL,
            model_kwargs={'device': 'cpu'},
            encode_kwargs={'normalize_embeddings': True}
        )
    except: return None

# T·ªëi ∆∞u: Ch·ªâ qu√©t l·∫°i PDF khi file index ch∆∞a t·ªìn t·∫°i ho·∫∑c user y√™u c·∫ßu
def load_vector_db(embeddings, force_rebuild=False):
    if not embeddings: return None
    
    # N·∫øu ƒë√£ c√≥ DB v√† kh√¥ng b·∫Øt bu·ªôc rebuild -> Load ngay (Nhanh)
    if os.path.exists(AppConfig.VECTOR_DB_PATH) and not force_rebuild:
        try:
            return FAISS.load_local(AppConfig.VECTOR_DB_PATH, embeddings, allow_dangerous_deserialization=True)
        except: pass # N·∫øu l·ªói file c≈© th√¨ rebuild

    # Rebuild (Ch·∫≠m h∆°n ch√∫t)
    if not os.path.exists(AppConfig.PDF_DIR):
        os.makedirs(AppConfig.PDF_DIR, exist_ok=True)
        return None

    pdf_files = glob.glob(os.path.join(AppConfig.PDF_DIR, "*.pdf"))
    if not pdf_files: return None

    docs = []
    for pdf_path in pdf_files:
        try:
            reader = PdfReader(pdf_path)
            for page_num, page in enumerate(reader.pages):
                text = page.extract_text()
                if text and len(text.strip()) > 50:
                    docs.append(Document(
                        page_content=text,
                        metadata={"source": os.path.basename(pdf_path), "page": page_num + 1}
                    ))
        except: continue
    
    if docs:
        splitter = RecursiveCharacterTextSplitter(
            chunk_size=AppConfig.CHUNK_SIZE,
            chunk_overlap=AppConfig.CHUNK_OVERLAP
        )
        splits = splitter.split_documents(docs)
        vector_db = FAISS.from_documents(splits, embeddings)
        vector_db.save_local(AppConfig.VECTOR_DB_PATH)
        return vector_db
    return None

def get_rag_response(client, vector_db, query):
    """X·ª≠ l√Ω logic RAG: T√¨m ki·∫øm -> T·∫°o prompt -> Stream tr·∫£ l·ªùi"""
    
    # 1. T√¨m ki·∫øm ng·ªØ c·∫£nh
    context_text = ""
    sources = []
    
    if vector_db:
        results = vector_db.similarity_search_with_score(query, k=AppConfig.TOP_K_RETRIEVAL)
        context_parts = []
        for doc, score in results:
            # L·ªçc b·ªõt k·∫øt qu·∫£ kh√¥ng li√™n quan (score c√†ng nh·ªè c√†ng t·ªët v·ªõi L2 distance, nh∆∞ng FAISS m·∫∑c ƒë·ªãnh similarity score kh√°c)
            # V·ªõi FAISS m·∫∑c ƒë·ªãnh cosine similarity hay L2 c·∫ßn check k·ªπ. ·ªû ƒë√¢y ta l·∫•y top K th√¥i.
            src = doc.metadata.get('source', 'T√†i li·ªáu')
            page = doc.metadata.get('page', '1')
            content = doc.page_content.replace("\n", " ").strip()
            
            context_parts.append(f"Content: {content}\nSource: {src} (Page {page})")
            sources.append(f"{src} - Trang {page}")
        
        context_text = "\n\n".join(context_parts)

    # 2. System Prompt (Guardrails)
    system_prompt = f"""B·∫°n l√† KTC Assistant - Tr·ª£ l√Ω ·∫£o h·ªó tr·ª£ h·ªçc t·∫≠p tr∆∞·ªùng THCS & THPT Ph·∫°m Ki·ªát.
    
    NHI·ªÜM V·ª§:
    - Tr·∫£ l·ªùi c√¢u h·ªèi d·ª±a tr√™n th√¥ng tin ƒë∆∞·ª£c cung c·∫•p trong [CONTEXT].
    - N·∫øu th√¥ng tin kh√¥ng c√≥ trong [CONTEXT], h√£y d√πng ki·∫øn th·ª©c chung nh∆∞ng n√≥i r√µ l√† "Theo ki·∫øn th·ª©c c·ªßa t√¥i...".
    - Lu√¥n tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát, gi·ªçng vƒÉn th√¢n thi·ªán, khuy·∫øn kh√≠ch h·ªçc sinh.
    - Tr√¨nh b√†y Markdown r√µ r√†ng (d√πng g·∫°ch ƒë·∫ßu d√≤ng, b√¥i ƒë·∫≠m √Ω ch√≠nh).
    
    [CONTEXT]:
    {context_text}
    """

    # 3. G·ªçi API
    try:
        stream = client.chat.completions.create(
            model=AppConfig.LLM_MODEL,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": query}
            ],
            stream=True,
            temperature=0.3,
            max_tokens=2000
        )
        return stream, list(set(sources))
    except Exception as e:
        return f"Error: {str(e)}", []

# ==============================================================================
# 4. CH∆Ø∆†NG TR√åNH CH√çNH
# ==============================================================================

def main():
    if not DEPENDENCIES_OK:
        st.error(f"‚ö†Ô∏è L·ªói th∆∞ vi·ªán: {IMPORT_ERROR}. Vui l√≤ng ch·∫°y `pip install -r requirements.txt`")
        st.stop()
        
    inject_custom_css()
    
    # --- SIDEBAR: N∆°i th·ªÉ hi·ªán th∆∞∆°ng hi·ªáu ---
    with st.sidebar:
        # 1. Logo KTC (D·ª± √°n)
        if os.path.exists(AppConfig.LOGO_PROJECT):
            st.image(AppConfig.LOGO_PROJECT, use_container_width=True)
        
        # 2. Th√¥ng tin d·ª± √°n
        st.markdown("""
        <div class="project-card">
            <h3 style="margin:0; color:#0277bd;">KTC CHATBOT</h3>
            <p style="font-size:0.8rem; color:gray;">Tr·ª£ l√Ω ·∫£o th√¥ng minh</p>
            <hr style="margin:10px 0;">
            <div class="author-info">
                <b>üë®‚Äçüíª T√°c gi·∫£:</b> T√° T√πng & B·∫£o Chung<br>
                <b>üßë‚Äçüè´ GVHD:</b> Th·∫ßy Khanh<br>
                <b>üèÜ D·ª± √°n:</b> KHKT 2024-2025
            </div>
        </div>
        """, unsafe_allow_html=True)
        
        # 3. C√¥ng c·ª•
        with st.expander("üõ†Ô∏è C√†i ƒë·∫∑t & D·ªØ li·ªáu"):
            if st.button("üîÑ N·∫°p l·∫°i d·ªØ li·ªáu g·ªëc", use_container_width=True):
                with st.spinner("ƒêang x·ª≠ l√Ω PDF..."):
                    embeddings = load_embedding_model()
                    st.session_state.vector_db = load_vector_db(embeddings, force_rebuild=True)
                st.success("D·ªØ li·ªáu ƒë√£ c·∫≠p nh·∫≠t!")
                time.sleep(1)
                st.rerun()
                
            if st.button("üóëÔ∏è X√≥a l·ªãch s·ª≠ chat", use_container_width=True):
                st.session_state.messages = []
                st.rerun()

        # 4. Logo Tr∆∞·ªùng (Footer Sidebar)
        st.markdown("---")
        if os.path.exists(AppConfig.LOGO_SCHOOL):
            st.markdown('<div class="school-logo-container">', unsafe_allow_html=True)
            st.image(AppConfig.LOGO_SCHOOL, width=120, caption="THCS & THPT Ph·∫°m Ki·ªát")
            st.markdown('</div>', unsafe_allow_html=True)

    # --- MAIN UI ---
    
    # Header ·∫•n t∆∞·ª£ng
    st.markdown(f"""
    <div class="main-header">
        <div class="header-title">
            <h1>KTC ASSISTANT</h1>
            <p>Knowledge in Technology & Computer Science</p>
        </div>
        </div>
    """, unsafe_allow_html=True)

    # Init Session State
    if "messages" not in st.session_state:
        st.session_state.messages = [
            {"role": "assistant", "content": "üëã Ch√†o b·∫°n! M√¨nh l√† KTC Assistant. M√¨nh c√≥ th·ªÉ gi√∫p g√¨ cho b√†i nghi√™n c·ª©u ho·∫∑c b√†i t·∫≠p Tin h·ªçc c·ªßa b·∫°n h√¥m nay?"}
        ]
    
    if "vector_db" not in st.session_state:
        with st.spinner("üöÄ ƒêang kh·ªüi ƒë·ªông h·ªá th·ªëng AI..."):
            embeddings = load_embedding_model()
            st.session_state.vector_db = load_vector_db(embeddings)

    groq_client = load_groq_client()

    # Hi·ªÉn th·ªã l·ªãch s·ª≠ chat
    for msg in st.session_state.messages:
        # Avatar t√πy ch·ªânh: Bot d√πng logo KTC (n·∫øu c√≥) ho·∫∑c icon robot
        avatar = "üßë‚Äçüéì" if msg["role"] == "user" else (AppConfig.LOGO_PROJECT if os.path.exists(AppConfig.LOGO_PROJECT) else "ü§ñ")
        with st.chat_message(msg["role"], avatar=avatar):
            st.markdown(msg["content"])

    # G·ª£i √Ω c√¢u h·ªèi (X·ª≠ l√Ω th√¥ng minh kh√¥ng reload x·∫•u)
    if len(st.session_state.messages) < 2:
        st.markdown("#### üí° G·ª£i √Ω c√¢u h·ªèi:")
        cols = st.columns(3)
        prompt_from_button = None
        
        if cols[0].button("üìù C·∫•u tr√∫c b√†i b√°o c√°o?"):
            prompt_from_button = "H√£y cho t√¥i d√†n √Ω chi ti·∫øt b√†i b√°o c√°o d·ª± √°n KHKT."
        if cols[1].button("üêç Code Python c∆° b·∫£n?"):
            prompt_from_button = "Vi·∫øt cho t√¥i m·ªôt ƒëo·∫°n code Python t√≠nh t·ªïng danh s√°ch."
        if cols[2].button("üè´ Gi·ªõi thi·ªáu v·ªÅ tr∆∞·ªùng?"):
            prompt_from_button = "Gi·ªõi thi·ªáu ƒë√¥i n√©t v·ªÅ tr∆∞·ªùng THCS & THPT Ph·∫°m Ki·ªát."
            
        if prompt_from_button:
            # G√°n v√†o input gi·∫£ l·∫≠p
            st.session_state.temp_input = prompt_from_button
            st.rerun()

    # X·ª≠ l√Ω input (t·ª´ chat box ho·∫∑c t·ª´ button g·ª£i √Ω)
    if "temp_input" in st.session_state and st.session_state.temp_input:
        user_input = st.session_state.temp_input
        del st.session_state.temp_input # X√≥a ngay sau khi l·∫•y
    else:
        user_input = st.chat_input("Nh·∫≠p c√¢u h·ªèi c·ªßa b·∫°n t·∫°i ƒë√¢y...")

    if user_input:
        # 1. Hi·ªÉn th·ªã c√¢u h·ªèi User
        st.session_state.messages.append({"role": "user", "content": user_input})
        with st.chat_message("user", avatar="üßë‚Äçüéì"):
            st.markdown(user_input)

        # 2. X·ª≠ l√Ω tr·∫£ l·ªùi
        with st.chat_message("assistant", avatar=AppConfig.LOGO_PROJECT if os.path.exists(AppConfig.LOGO_PROJECT) else "ü§ñ"):
            response_container = st.empty()
            
            # Hi·ªáu ·ª©ng Spinner ƒë·∫πp
            with st.spinner("üß† KTC ƒëang suy nghƒ©..."):
                if not groq_client:
                    st.error("‚ùå Ch∆∞a k·∫øt n·ªëi API Groq.")
                    st.stop()
                    
                stream, sources = get_rag_response(groq_client, st.session_state.vector_db, user_input)
            
            # Streaming text
            full_response = ""
            if isinstance(stream, str): # Tr∆∞·ªùng h·ª£p l·ªói
                response_container.error(stream)
                full_response = stream
            else:
                for chunk in stream:
                    if chunk.choices[0].delta.content:
                        content = chunk.choices[0].delta.content
                        full_response += content
                        response_container.markdown(full_response + "‚ñå")
                response_container.markdown(full_response)
            
            # Hi·ªÉn th·ªã ngu·ªìn (Minh ch·ª©ng KHKT)
            if sources:
                with st.expander("üìö Ngu·ªìn tham kh·∫£o (Minh ch·ª©ng)"):
                    for src in sources:
                        st.caption(f"‚Ä¢ {src}")
            
            # L∆∞u l·ªãch s·ª≠
            st.session_state.messages.append({"role": "assistant", "content": full_response})

if __name__ == "__main__":
    main()