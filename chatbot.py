import os
import glob
import base64
import streamlit as st
import shutil
import pickle
import re
import uuid
import json
from pathlib import Path
from typing import List, Tuple, Optional, Dict, Generator

# --- Imports v·ªõi x·ª≠ l√Ω l·ªói ---
try:
    import nest_asyncio
    nest_asyncio.apply() # B·∫Øt bu·ªôc cho LlamaParse ch·∫°y trong Streamlit
    from llama_parse import LlamaParse 
    
    from langchain_text_splitters import RecursiveCharacterTextSplitter
    from langchain_community.vectorstores import FAISS
    from langchain_community.retrievers import BM25Retriever
    from langchain.retrievers import EnsembleRetriever
    from langchain_huggingface import HuggingFaceEmbeddings
    from langchain_core.documents import Document
    from groq import Groq
    # Rerank optimization
    from flashrank import Ranker, RerankRequest
    DEPENDENCIES_OK = True
except ImportError as e:
    DEPENDENCIES_OK = False
    IMPORT_ERROR = str(e)

# ==============================
# 1. C·∫§U H√åNH H·ªÜ TH·ªêNG (CONFIG) 
# ==============================

st.set_page_config(
    page_title="KTC Chatbot - THCS & THPT Ph·∫°m Ki·ªát",
    page_icon="LOGO.jpg",
    layout="wide",
    initial_sidebar_state="expanded"
)

class AppConfig:
    # Model Config
    LLM_MODEL = 'llama-3.1-8b-instant'

    EMBEDDING_MODEL = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
    RERANK_MODEL_NAME = "ms-marco-TinyBERT-L-2-v2"

    # Paths - CHU·∫®N KHOA H·ªåC
    PDF_DIR = "PDF_KNOWLEDGE"
    MANIFEST_FILE = "manifest.json" # Ground Truth Metadata
    VECTOR_DB_PATH = "faiss_db_index"
    RERANK_CACHE = "./opt"
    PROCESSED_MD_DIR = "PROCESSED_MD" 

    # Assets
    LOGO_PROJECT = "LOGO.jpg"
    LOGO_SCHOOL = "LOGO PKS.png"

    # RAG Parameters
    RETRIEVAL_K = 30       
    FINAL_K = 5            
    
    # Hybrid Search Weights
    BM25_WEIGHT = 0.4      
    FAISS_WEIGHT = 0.6     

    LLM_TEMPERATURE = 0.0 # Deterministic output for Science

    # Hard Filter for KHKT
    VALID_BO_SACH = "K·∫øt n·ªëi tri th·ª©c v·ªõi cu·ªôc s·ªëng"

# ===============================
# 2. X·ª¨ L√ù GIAO DI·ªÜN (UI MANAGER ) 
# ===============================

class UIManager:
    @staticmethod
    def get_img_as_base64(file_path):
        if not os.path.exists(file_path):
            return ""
        with open(file_path, "rb") as f:
            data = f.read()
        return base64.b64encode(data).decode()

    @staticmethod
    def inject_custom_css():
        st.markdown("""
        <style>
            @import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;600;800&display=swap');
            html, body, [class*="css"], .stMarkdown, .stButton, .stTextInput, .stChatInput {
                font-family: 'Inter', sans-serif !important;
            }
            section[data-testid="stSidebar"] {
                background-color: #f8f9fa; border-right: 1px solid #e9ecef;
            }
            .project-card {
                background: white; padding: 15px; border-radius: 12px;
                box-shadow: 0 2px 8px rgba(0,0,0,0.05); margin-bottom: 20px;
                border: 1px solid #dee2e6;
            }
            .project-title {
                color: #0077b6; font-weight: 800; font-size: 1.1rem;
                margin-bottom: 5px; text-align: center; text-transform: uppercase;
            }
            .project-sub {
                font-size: 0.8rem; color: #6c757d; text-align: center;
                margin-bottom: 15px; font-style: italic;
            }
            .main-header {
                background: linear-gradient(135deg, #023e8a 0%, #0077b6 100%);
                padding: 1.5rem 2rem; border-radius: 15px; color: white;
                margin-bottom: 2rem; box-shadow: 0 8px 20px rgba(0, 119, 182, 0.3);
                display: flex; align-items: center; justify-content: space-between;
            }
            .header-left h1 {
                color: #caf0f8 !important; font-weight: 900; margin: 0;
                font-size: 2.2rem; letter-spacing: -0.5px;
            }
            .header-left p {
                color: #e0fbfc; margin: 5px 0 0 0; font-size: 1rem; opacity: 0.9;
            }
            .header-right img {
                border-radius: 50%; border: 3px solid rgba(255,255,255,0.3);
                box-shadow: 0 4px 10px rgba(0,0,0,0.2); width: 100px; height: 100px;
                object-fit: cover;
            }
            [data-testid="stChatMessageContent"] {
                border-radius: 15px !important; padding: 1rem !important;
                box-shadow: 0 2px 4px rgba(0,0,0,0.05);
            }
            [data-testid="stChatMessageContent"]:has(+ [data-testid="stChatMessageAvatar"]) {
                background: #e3f2fd; color: #0d47a1;
            }
            [data-testid="stChatMessageContent"]:not(:has(+ [data-testid="stChatMessageAvatar"])) {
                background: white; border: 1px solid #e9ecef;
                border-left: 5px solid #00b4d8;
            }
            /* Style cho Citation chu·∫©n KHKT */
            .citation-source {
                font-size: 0.75em;
                color: #333; 
                background-color: #f1f3f5;
                padding: 8px 12px;
                border-radius: 8px;
                font-weight: 500;
                margin-left: 0px;
                display: block;
                border-left: 4px solid #d63384; /* M√†u h·ªìng ƒë·∫≠m n·ªïi b·∫≠t */
                line-height: 1.4;
            }
            div.stButton > button {
                border-radius: 8px; background-color: white; color: #0077b6;
                border: 1px solid #90e0ef; transition: all 0.2s;
            }
            div.stButton > button:hover {
                background-color: #0077b6; color: white;
                border-color: #0077b6; box-shadow: 0 4px 6px rgba(0,0,0,0.1);
            }
            #MainMenu {visibility: hidden;}
            footer {visibility: hidden;}
        </style>
        """, unsafe_allow_html=True)

    @staticmethod
    def render_sidebar():
        with st.sidebar:
            if os.path.exists(AppConfig.LOGO_SCHOOL):
                col1, col2, col3 = st.columns([1, 2, 1])
                with col2:
                    st.image(AppConfig.LOGO_SCHOOL, use_container_width=True)
                st.markdown("<div style='text-align:center; font-weight:700; color:#023e8a; margin-bottom:20px;'>THCS & THPT PH·∫†M KI·ªÜT</div>", unsafe_allow_html=True)

            st.markdown("""
            <div class="project-card">
                <div class="project-title">KTC CHATBOT</div>
                <div class="project-sub">S·∫£n ph·∫©m d·ª± thi KHKT c·∫•p T·ªânh</div>
                <hr style="margin: 10px 0; border-top: 1px dashed #dee2e6;">
                <div style="font-size: 0.9rem; line-height: 1.6;">
                    <div style="display: flex; justify-content: space-between;">
                        <span style="font-weight: 600; color: #555;">T√°c gi·∫£:</span>
                        <span style="text-align: right; color: #222;"><b>B√πi T√° T√πng</b><br><b>Cao S·ªπ B·∫£o Chung</b></span>
                    </div>
                    <div style="display: flex; justify-content: space-between; margin-top: 8px;">
                        <span style="font-weight: 600; color: #555;">GVHD:</span>
                        <span style="text-align: right; color: #222;">Th·∫ßy <b>Nguy·ªÖn Th·∫ø Khanh</b></span>
                    </div>
                    <div style="display: flex; justify-content: space-between; margin-top: 8px;">
                        <span style="font-weight: 600; color: #555;">NƒÉm h·ªçc:</span>
                        <span style="text-align: right; color: #222;"><b>2025 - 2026</b></span>
                    </div>
                </div>
            </div>
            """, unsafe_allow_html=True)
            
            st.markdown("### ‚öôÔ∏è Ti·ªán √≠ch")
            if st.button("üóëÔ∏è X√≥a l·ªãch s·ª≠ chat", use_container_width=True):
                st.session_state.messages = []
                st.rerun()

            if st.button("üîÑ C·∫≠p nh·∫≠t d·ªØ li·ªáu (Manifest)", use_container_width=True):
                if os.path.exists(AppConfig.VECTOR_DB_PATH):
                    shutil.rmtree(AppConfig.VECTOR_DB_PATH)
                st.session_state.pop('retriever_engine', None)
                st.rerun()

    @staticmethod
    def render_header():
        logo_nhom_b64 = UIManager.get_img_as_base64(AppConfig.LOGO_PROJECT)
        img_html = f'<img src="data:image/jpeg;base64,{logo_nhom_b64}" alt="Logo">' if logo_nhom_b64 else ""

        st.markdown(f"""
        <div class="main-header">
            <div class="header-left">
                <h1>KTC CHATBOT</h1>
                <p style="font-size: 1.1rem; margin-top: 5px;">H·ªçc Tin d·ªÖ d√†ng - Thao t√°c v·ªØng v√†ng</p>
            </div>
            <div class="header-right">
                {img_html}
            </div>
        </div>
        """, unsafe_allow_html=True)

# ==================================
# 3. LOGIC BACKEND - VERIFIABLE HYBRID RAG
# ==================================

class RAGEngine:
    @staticmethod
    @st.cache_resource(show_spinner=False)
    def load_groq_client():
        try:
            api_key = st.secrets.get("GROQ_API_KEY") or os.environ.get("GROQ_API_KEY")
            if not api_key:
                return None
            return Groq(api_key=api_key)
        except Exception:
            return None

    @staticmethod
    @st.cache_resource(show_spinner=False)
    def load_embedding_model():
        try:
            return HuggingFaceEmbeddings(
                model_name=AppConfig.EMBEDDING_MODEL,
                model_kwargs={'device': 'cpu'},
                encode_kwargs={'normalize_embeddings': True}
            )
        except Exception as e:
            st.error(f"L·ªói t·∫£i Embedding: {e}")
            return None

    @staticmethod
    @st.cache_resource(show_spinner=False)
    def load_reranker():
        try:
            return Ranker(model_name=AppConfig.RERANK_MODEL_NAME, cache_dir=AppConfig.RERANK_CACHE)
        except Exception as e:
            return None

    # --- [NEW] MANIFEST LOADER (Ground Truth) ---
    @staticmethod
    def _load_manifest() -> Dict:
        manifest_path = os.path.join(AppConfig.PDF_DIR, AppConfig.MANIFEST_FILE)
        if not os.path.exists(manifest_path):
            return {}
        try:
            with open(manifest_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception:
            return {}

    @staticmethod
    def _structural_chunking(text: str, manifest_meta: dict) -> List[Document]:
        """
        Ph√¢n m·∫£nh c·∫•u tr√∫c k·∫øt h·ª£p v·ªõi Metadata ch√≠nh x√°c t·ª´ Manifest
        """
        lines = text.split('\n')
        chunks = []
        
        current_chapter = "Ch∆∞∆°ng m·ªü ƒë·∫ßu"
        current_lesson = "B√†i m·ªü ƒë·∫ßu"
        current_section = "N·ªôi dung"
        
        buffer = []

        # --- REGEX PATTERNS CHO SGK VI·ªÜT NAM ---
        p_chapter = re.compile(r'^#*\s*\**\s*(CH∆Ø∆†NG|Ch∆∞∆°ng)\s+([IVX0-9]+).*$', re.IGNORECASE)
        p_lesson = re.compile(r'^#*\s*\**\s*(B√ÄI|B√†i)\s+([0-9]+).*$', re.IGNORECASE)
        p_section = re.compile(r'^(###\s+|[IV0-9]+\.\s+|[a-z]\)\s+).*')

        def clean_header(text):
            return text.replace('#', '').replace('*', '').strip()

        def commit_chunk(buf, base_meta):
            if not buf: return
            content = "\n".join(buf).strip()
            if len(content) < 50: return 
            
            chunk_uid = str(uuid.uuid4())[:8] # Generate 8-char UID
            
            # Merge Metadata: Manifest (Static) + Text Analysis (Dynamic)
            new_meta = base_meta.copy()
            new_meta.update({
                "chunk_uid": chunk_uid,
                "chapter": current_chapter,
                "lesson": current_lesson,
                "section": current_section,
                # Context string for debug/search
                "context_str": f"{current_chapter} > {current_lesson} > {current_section}" 
            })
            
            chunks.append(Document(page_content=content, metadata=new_meta))

        for line in lines:
            line_stripped = line.strip()
            if not line_stripped: continue
            
            if p_chapter.match(line_stripped):
                commit_chunk(buffer, manifest_meta)
                buffer = []
                current_chapter = clean_header(line_stripped)
                current_lesson = "T·ªïng quan ch∆∞∆°ng"
                current_section = "Gi·ªõi thi·ªáu"
            
            elif p_lesson.match(line_stripped):
                commit_chunk(buffer, manifest_meta)
                buffer = []
                current_lesson = clean_header(line_stripped)
                current_section = "T·ªïng quan b√†i"
                
            elif p_section.match(line_stripped) or line_stripped.startswith("### "):
                commit_chunk(buffer, manifest_meta)
                buffer = []
                current_section = clean_header(line_stripped)
                
            elif line_stripped.startswith("# "): 
                commit_chunk(buffer, manifest_meta)
                buffer = []
                current_chapter = clean_header(line_stripped)
            elif line_stripped.startswith("## "): 
                commit_chunk(buffer, manifest_meta)
                buffer = []
                current_lesson = clean_header(line_stripped)
            else:
                buffer.append(line)
        
        commit_chunk(buffer, manifest_meta)
        return chunks

    @staticmethod
    def _parse_pdf_with_llama(file_path: str) -> str:
        os.makedirs(AppConfig.PROCESSED_MD_DIR, exist_ok=True)
        file_name = os.path.basename(file_path)
        md_file_path = os.path.join(AppConfig.PROCESSED_MD_DIR, f"{file_name}.md")
        
        if os.path.exists(md_file_path):
            with open(md_file_path, "r", encoding="utf-8") as f:
                return f.read()
        
        llama_api_key = st.secrets.get("LLAMA_CLOUD_API_KEY")
        if not llama_api_key:
            return "ERROR: Missing LLAMA_CLOUD_API_KEY"

        try:
            parser = LlamaParse(
                api_key=llama_api_key,
                result_type="markdown",
                language="vi",
                verbose=True,
                parsing_instruction="ƒê√¢y l√† t√†i li·ªáu gi√°o khoa Tin h·ªçc chu·∫©n. H√£y gi·ªØ nguy√™n ƒë·ªãnh d·∫°ng b·∫£ng bi·ªÉu, code block v√† c·∫•u tr√∫c ch∆∞∆°ng m·ª•c (#, ##, ###)."
            )
            documents = parser.load_data(file_path)
            markdown_text = documents[0].text
            
            with open(md_file_path, "w", encoding="utf-8") as f:
                f.write(markdown_text)
            
            return markdown_text
        except Exception as e:
            return f"Error parsing {file_name}: {str(e)}"

    @staticmethod
    def _read_and_process_files(pdf_dir: str) -> List[Document]:
        """
        Quy tr√¨nh x·ª≠ l√Ω file d·ª±a tr√™n MANIFEST (Strict Mode)
        """
        if not os.path.exists(pdf_dir):
            return []
        
        # 1. Load Manifest
        manifest = RAGEngine._load_manifest()
        if not manifest:
            st.warning("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y file 'manifest.json' ho·∫∑c file b·ªã l·ªói. Vui l√≤ng ki·ªÉm tra th∆∞ m·ª•c PDF_KNOWLEDGE.")
            return []

        pdf_files = glob.glob(os.path.join(pdf_dir, "*.pdf"))
        all_chunks: List[Document] = []
        status_text = st.empty()

        for file_path in pdf_files:
            source_file = os.path.basename(file_path)
            
            # 2. Manifest Validation Check
            if source_file not in manifest:
                st.toast(f"üö´ B·ªè qua {source_file}: Kh√¥ng c√≥ trong Manifest.", icon="‚ö†Ô∏è")
                continue
            
            file_meta = manifest[source_file]
            
            # 3. Content Guard (B·ªô s√°ch Filter)
            if file_meta.get("bo_sach") != AppConfig.VALID_BO_SACH:
                st.toast(f"üö´ B·ªè qua {source_file}: Kh√¥ng thu·ªôc b·ªô '{AppConfig.VALID_BO_SACH}'", icon="üõë")
                continue

            status_text.text(f"‚è≥ ƒêang x·ª≠ l√Ω: {source_file} ({file_meta['mon']} {file_meta['lop']})...")
            
            markdown_content = RAGEngine._parse_pdf_with_llama(file_path)
            
            if "ERROR" not in markdown_content and len(markdown_content) > 50:
                 # Truy·ªÅn Metadata chu·∫©n t·ª´ Manifest v√†o chunker
                 file_chunks = RAGEngine._structural_chunking(markdown_content, file_meta)
                 all_chunks.extend(file_chunks)
            else:
                st.error(f"L·ªói ƒë·ªçc n·ªôi dung file: {source_file}")
                
        status_text.empty()
        return all_chunks

    @staticmethod
    def build_hybrid_retriever(embeddings):
        if not embeddings: return None

        vector_db = None
        if os.path.exists(AppConfig.VECTOR_DB_PATH):
            try:
                vector_db = FAISS.load_local(AppConfig.VECTOR_DB_PATH, embeddings, allow_dangerous_deserialization=True)
            except Exception: pass

        if not vector_db:
            chunk_docs = RAGEngine._read_and_process_files(AppConfig.PDF_DIR)
            if not chunk_docs:
                st.error(f"Ch∆∞a c√≥ d·ªØ li·ªáu h·ª£p l·ªá trong {AppConfig.PDF_DIR}. Vui l√≤ng ki·ªÉm tra Manifest.")
                return None
            
            vector_db = FAISS.from_documents(chunk_docs, embeddings)
            vector_db.save_local(AppConfig.VECTOR_DB_PATH)

        try:
            docstore_docs = list(vector_db.docstore._dict.values())
            bm25_retriever = BM25Retriever.from_documents(docstore_docs)
            bm25_retriever.k = AppConfig.RETRIEVAL_K

            faiss_retriever = vector_db.as_retriever(
                search_type="mmr",
                search_kwargs={"k": AppConfig.RETRIEVAL_K, "lambda_mult": 0.5}
            )

            ensemble_retriever = EnsembleRetriever(
                retrievers=[bm25_retriever, faiss_retriever],
                weights=[AppConfig.BM25_WEIGHT, AppConfig.FAISS_WEIGHT]
            )
            return ensemble_retriever
        except Exception:
            return vector_db.as_retriever(search_kwargs={"k": AppConfig.RETRIEVAL_K})
    
    @staticmethod
    def _sanitize_output(text: str) -> str:
        """
        V·ªá sinh vƒÉn b·∫£n: Lo·∫°i b·ªè k√Ω t·ª± CJK (Trung/H√†n/Nh·∫≠t)
        """
        cjk_pattern = re.compile(r'[\u4e00-\u9fff\u3400-\u4dbf\u3040-\u309f\u30a0-\u30ff\uac00-\ud7af]+')
        text = cjk_pattern.sub("", text) 
        return text

    @staticmethod
    def generate_response(client, retriever, query) -> Generator[str, None, None]:
        if not retriever:
            yield "H·ªá th·ªëng ƒëang kh·ªüi t·∫°o... vui l√≤ng ch·ªù gi√¢y l√°t."
            return
        
        # --- T·∫¶NG 1: RETRIEVAL ---
        initial_docs = retriever.invoke(query)
        final_docs = []
        try:
            ranker = RAGEngine.load_reranker()
            if ranker and initial_docs:
                passages = [
                    {"id": str(i), "text": d.page_content, "meta": d.metadata} 
                    for i, d in enumerate(initial_docs)
                ]
                rerank_req = RerankRequest(query=query, passages=passages)
                results = ranker.rank(rerank_req)
                for res in results[:AppConfig.FINAL_K]:
                    final_docs.append(Document(page_content=res["text"], metadata=res["meta"]))
            else:
                final_docs = initial_docs[:AppConfig.FINAL_K]
        except Exception:
            final_docs = initial_docs[:AppConfig.FINAL_K]

        if not final_docs:
            yield "Kh√¥ng t√¨m th·∫•y th√¥ng tin ph√π h·ª£p trong t√†i li·ªáu KNTT hi·ªán c√≥."
            return

        # --- T·∫¶NG 2: BUILDING REGISTRY (S·ªî C√ÅI √ÅNH X·∫† NGU·ªíN CHU·∫®N KHKT) ---
        citation_registry = {} 
        context_parts = []

        for doc in final_docs:
            uid = doc.metadata.get('chunk_uid')
            if not uid: continue
            
            # L·∫•y Metadata chu·∫©n t·ª´ Manifest (ƒë√£ inject v√†o chunk)
            m = doc.metadata
            mon = m.get('mon', 'Tin h·ªçc')
            lop = m.get('lop', '')
            bo_sach = m.get('bo_sach', AppConfig.VALID_BO_SACH)
            loai_lieu = m.get('loai_tai_lieu', 'T√†i li·ªáu')
            chapter = m.get('chapter', 'Ch∆∞∆°ng ?')
            lesson = m.get('lesson', 'B√†i ?')
            nxb = m.get('nxb', 'NXB Gi√°o d·ª•c Vi·ªát Nam')
            
            # Format hi·ªÉn th·ªã h·ªçc thu·∫≠t
            citation_html = f"""
            <b>üìò {mon} {lop} - {bo_sach}</b><br>
            {loai_lieu} &gt; {chapter} &gt; {lesson}<br>
            <i>{nxb}</i>
            """
            
            citation_registry[uid] = citation_html
            
            # ƒê∆∞a v√†o prompt cho AI
            context_parts.append(
                f"--- BEGIN CHUNK ---\nID: {uid}\nCONTENT: {doc.page_content}\n--- END CHUNK ---"
            )

        full_context = "\n".join(context_parts)

        # --- T·∫¶NG 3: PROMPT (NGHI√äM NG·∫∂T - CITATION GATED) ---
        
        system_prompt = f"""B·∫°n l√† KTC Chatbot, tr·ª£ l√Ω h·ªçc thu·∫≠t.
NHI·ªÜM V·ª§: Tr·∫£ l·ªùi c√¢u h·ªèi d·ª±a tr√™n [CONTEXT] t·ª´ b·ªô s√°ch "K·∫øt n·ªëi tri th·ª©c v·ªõi cu·ªôc s·ªëng".

QUY T·∫ÆC B·∫ÆT BU·ªòC (CITATION-GATED GENERATION):
1. D·ª±a ho√†n to√†n v√†o context ƒë·ªÉ tr·∫£ l·ªùi. Kh√¥ng b·ªãa ƒë·∫∑t.
2. TUY·ªÜT ƒê·ªêI KH√îNG t·ª± vi·∫øt ngu·ªìn, t√™n s√°ch trong l·ªùi gi·∫£i (H·ªá th·ªëng s·∫Ω t·ª± th√™m ·ªü cu·ªëi).
3. KH√îNG ch√®n m√£ [REF] lung tung.
4. Ch·ªçn ƒê√öNG 1 ƒëo·∫°n th√¥ng tin (chunk) quan tr·ªçng nh·∫•t.
5. K·∫æT TH√öC C√ÇU TR·∫¢ L·ªúI b·∫±ng c√∫ ph√°p: [FINAL_REF:xxxxxxxx] (xxxxxxxx l√† ID c·ªßa chunk).
6. N·∫øu kh√¥ng t√¨m th·∫•y th√¥ng tin: Tr·∫£ l·ªùi "Kh√¥ng t√¨m th·∫•y th√¥ng tin ph√π h·ª£p trong b·ªô s√°ch n√†y."

[CONTEXT]
{full_context}
"""
        
        try:
            completion = client.chat.completions.create(
                model=AppConfig.LLM_MODEL,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": query}
                ],
                stream=False, 
                temperature=AppConfig.LLM_TEMPERATURE,
                max_tokens=1500
            )
            raw_response = completion.choices[0].message.content.strip()

            if not raw_response:
                yield "H·ªá th·ªëng kh√¥ng th·ªÉ t·∫°o c√¢u tr·∫£ l·ªùi."
                return

            # --- T·∫¶NG 4: H·∫¨U X·ª¨ L√ù (VERIFICATION & REPLACEMENT) ---
            
            cleaned_response = RAGEngine._sanitize_output(raw_response)
            
            # Regex t√¨m FINAL_REF ·ªü cu·ªëi chu·ªói
            pattern_final_ref = r'\[FINAL_REF:([a-zA-Z0-9]{8})\]'
            match = re.search(pattern_final_ref, cleaned_response)
            
            final_display_text = ""

            if "Kh√¥ng t√¨m th·∫•y th√¥ng tin ph√π h·ª£p" in cleaned_response:
                final_display_text = "Kh√¥ng t√¨m th·∫•y th√¥ng tin ph√π h·ª£p trong b·ªô s√°ch n√†y."
            
            elif match:
                uid = match.group(1)
                # Gatekeeper check: ID c√≥ trong s·ªï c√°i kh√¥ng?
                if uid in citation_registry:
                    content_only = re.sub(pattern_final_ref, '', cleaned_response).strip()
                    
                    # HTML ngu·ªìn ƒë·∫πp chu·∫©n KHKT
                    source_html = f"<div class='citation-source'>{citation_registry[uid]}</div>"
                    
                    final_display_text = content_only + source_html
                else:
                    final_display_text = "Kh√¥ng t√¨m th·∫•y th√¥ng tin ph√π h·ª£p. (L·ªói x√°c th·ª±c ngu·ªìn)"
            else:
                final_display_text = "Kh√¥ng t√¨m th·∫•y th√¥ng tin ph√π h·ª£p trong t√†i li·ªáu hi·ªán c√≥."

            yield final_display_text

        except Exception as e:
            yield f"L·ªói x·ª≠ l√Ω h·ªá th·ªëng: {str(e)}"

# ===================
# 4. MAIN APPLICATION
# ===================

def main():
    if not DEPENDENCIES_OK:
        st.error(f"‚ö†Ô∏è Thi·∫øu th∆∞ vi·ªán: {IMPORT_ERROR}")
        st.stop()

    UIManager.inject_custom_css()
    UIManager.render_sidebar()
    UIManager.render_header()

    if "messages" not in st.session_state:
        st.session_state.messages = [{"role": "assistant", "content": "üëã Ch√†o b·∫°n! KTC Chatbot s·∫µn s√†ng h·ªó tr·ª£ tra c·ª©u ki·∫øn th·ª©c b·ªô s√°ch <b>K·∫øt n·ªëi tri th·ª©c v·ªõi cu·ªôc s·ªëng</b>."}]

    groq_client = RAGEngine.load_groq_client()

    if "retriever_engine" not in st.session_state:
        with st.spinner("üöÄ ƒêang kh·ªüi ƒë·ªông h·ªá th·ªëng tri th·ª©c s·ªë (Metadata-Driven Check)..."):
            embeddings = RAGEngine.load_embedding_model()
            st.session_state.retriever_engine = RAGEngine.build_hybrid_retriever(embeddings)
            if st.session_state.retriever_engine:
                st.toast("‚úÖ D·ªØ li·ªáu SGK KNTT ƒë√£ s·∫µn s√†ng!", icon="üìö")

    for msg in st.session_state.messages:
        bot_avatar = AppConfig.LOGO_PROJECT if os.path.exists(AppConfig.LOGO_PROJECT) else "ü§ñ"
        avatar = "üßë‚Äçüéì" if msg["role"] == "user" else bot_avatar
        with st.chat_message(msg["role"], avatar=avatar):
            st.markdown(msg["content"], unsafe_allow_html=True) 

    user_input = st.chat_input("Nh·∫≠p c√¢u h·ªèi h·ªçc t·∫≠p...")
    
    if user_input:
        st.session_state.messages.append({"role": "user", "content": user_input})
        with st.chat_message("user", avatar="üßë‚Äçüéì"):
            st.markdown(user_input)

        with st.chat_message("assistant", avatar=AppConfig.LOGO_PROJECT if os.path.exists(AppConfig.LOGO_PROJECT) else "ü§ñ"):
            response_placeholder = st.empty()
            
            response_gen = RAGEngine.generate_response(
                groq_client,
                st.session_state.retriever_engine,
                user_input
            )

            full_response = ""
            for chunk in response_gen:
                full_response += chunk
                response_placeholder.markdown(full_response + "‚ñå", unsafe_allow_html=True)
            
            response_placeholder.markdown(full_response, unsafe_allow_html=True)

            st.session_state.messages.append({"role": "assistant", "content": full_response})

if __name__ == "__main__":
    main()