"""
PROJECT: KTC CHATBOT - TR·ª¢ L√ù H·ªåC T·∫¨P TIN H·ªåC THPT
M√î H√åNH: RETRIEVAL-AUGMENTED GENERATION (RAG) N√ÇNG CAO
LEVEL: D·ª∞ √ÅN KHOA H·ªåC K·ª∏ THU·∫¨T C·∫§P QU·ªêC GIA (VISEF)
AUTHORS: B√ôI T√Å T√ôNG - CAO S·ª∏ B·∫¢O CHUNG
MENTOR: TH·∫¶Y NGUY·ªÑN TH·∫æ KHANH
SCHOOL: THCS & THPT PH·∫†M KI·ªÜT
"""

import os
import glob
import base64
import streamlit as st
import shutil
import pickle
import re
import uuid
import unicodedata 
import time
from pathlib import Path
from typing import List, Tuple, Optional, Dict, Generator, Any

# --- Imports AI Core Libraries ---
try:
    import nest_asyncio
    nest_asyncio.apply() 
    
    # Loaders & Splitters
    from langchain_community.document_loaders import PyPDFLoader
    from langchain_text_splitters import RecursiveCharacterTextSplitter
    
    # Vector Stores & Retrievers
    from langchain_community.vectorstores import FAISS
    from langchain_community.retrievers import BM25Retriever
    from langchain.retrievers import EnsembleRetriever
    from langchain_huggingface import HuggingFaceEmbeddings
    from langchain_core.documents import Document
    
    # LLM Integration
    from groq import Groq
    
    # Advanced RAG: Reranking
    from flashrank import Ranker, RerankRequest
    
    DEPENDENCIES_OK = True
except ImportError as e:
    DEPENDENCIES_OK = False
    IMPORT_ERROR = str(e)

# ==============================================================================
# 1. C·∫§U H√åNH H·ªÜ TH·ªêNG (CONFIGURATION) - GI·ªÆ NGUY√äN
# ==============================================================================

st.set_page_config(
    page_title="KTC Chatbot - THCS & THPT Ph·∫°m Ki·ªát",
    page_icon="LOGO.jpg",
    layout="wide",
    initial_sidebar_state="expanded"
)

class AppConfig:
    """
    L·ªõp ch·ª©a to√†n b·ªô tham s·ªë c·∫•u h√¨nh c·ªßa d·ª± √°n.
    T·∫≠p trung h√≥a c·∫•u h√¨nh gi√∫p d·ªÖ d√†ng tinh ch·ªânh khi thi ƒë·∫•u.
    """
    # --- MODEL AI CONFIG ---
    # S·ª≠ d·ª•ng Llama 3 b·∫£n 70B ho·∫∑c 8B t√πy v√†o API Key quota
    LLM_MODEL = 'llama3-70b-8192' 
    
    # Embedding: Multilingual ƒë·ªÉ h·ªó tr·ª£ ti·∫øng Vi·ªát t·ªët nh·∫•t
    EMBEDDING_MODEL = "dangvantuan/vietnamese-embedding" # Model VNI t·ªët nh·∫•t hi·ªán t·∫°i
    # EMBEDDING_MODEL = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2" # Backup

    # Reranking Model (Ch·∫°y local si√™u nh·∫π, kh√¥ng t·ªën API)
    RERANK_MODEL_NAME = "ms-marco-MiniLM-L-12-v2"

    # --- PATHS ---
    PDF_DIR = "PDF_KNOWLEDGE"           # Th∆∞ m·ª•c ch·ª©a PDF ƒë·∫ßu v√†o
    VECTOR_DB_PATH = "faiss_db_index"   # Th∆∞ m·ª•c l∆∞u Index FAISS
    RERANK_CACHE = "./opt"              # Cache cho model Rerank
    PROCESSED_MD_DIR = "PROCESSED_MD"   # Cache file markdown ƒë√£ x·ª≠ l√Ω

    # --- ASSETS ---
    LOGO_PROJECT = "LOGO.jpg"
    LOGO_SCHOOL = "LOGO PKS.png"

    # --- HYPERPARAMETERS CHO RAG (TH√îNG S·ªê K·ª∏ THU·∫¨T) ---
    CHUNK_SIZE = 800       # K√≠ch th∆∞·ªõc ƒëo·∫°n c·∫Øt
    CHUNK_OVERLAP = 200    # ƒê·ªô ch·ªìng l·∫•p
    RETRIEVAL_K = 20       # S·ªë l∆∞·ª£ng documents l·∫•y ·ªü t·∫ßng 1 (Retrieval)
    FINAL_K = 5            # S·ªë l∆∞·ª£ng documents l·∫•y ·ªü t·∫ßng 2 (Rerank)
    
    # Tr·ªçng s·ªë Hybrid Search (Ensemble)
    BM25_WEIGHT = 0.4      # ∆Øu ti√™n t·ª´ kh√≥a ch√≠nh x√°c (40%)
    FAISS_WEIGHT = 0.6     # ∆Øu ti√™n ng·ªØ nghƒ©a (60%)

    LLM_TEMPERATURE = 0.1  # ƒê·ªô s√°ng t·∫°o th·∫•p ƒë·ªÉ ƒë·∫£m b·∫£o ch√≠nh x√°c SGK

    @staticmethod
    def init_folders():
        """Kh·ªüi t·∫°o c·∫•u tr√∫c th∆∞ m·ª•c n·∫øu ch∆∞a c√≥."""
        for path in [AppConfig.PDF_DIR, AppConfig.VECTOR_DB_PATH, AppConfig.PROCESSED_MD_DIR]:
            os.makedirs(path, exist_ok=True)

# ==============================================================================
# 2. UI MANAGER - GI·ªÆ NGUY√äN B·∫§T DI B·∫§T D·ªäCH THEO Y√äU C·∫¶U
# ==============================================================================

class UIManager:
    @staticmethod
    def get_img_as_base64(file_path):
        if not os.path.exists(file_path):
            return ""
        with open(file_path, "rb") as f:
            data = f.read()
        return base64.b64encode(data).decode()

    @staticmethod
    def inject_custom_css():
        # CSS c·ªßa th·∫ßy Khanh gi·ªØ nguy√™n 100%
        st.markdown("""
        <style>
            @import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;600;800&display=swap');
            html, body, [class*="css"], .stMarkdown, .stButton, .stTextInput, .stChatInput {
                font-family: 'Inter', sans-serif !important;
            }
            section[data-testid="stSidebar"] {
                background-color: #f8f9fa; border-right: 1px solid #e9ecef;
            }
            .project-card {
                background: white; padding: 15px; border-radius: 12px;
                box-shadow: 0 2px 8px rgba(0,0,0,0.05); margin-bottom: 20px;
                border: 1px solid #dee2e6;
            }
            .project-title {
                color: #0077b6; font-weight: 800; font-size: 1.1rem;
                margin-bottom: 5px; text-align: center; text-transform: uppercase;
            }
            .project-sub {
                font-size: 0.8rem; color: #6c757d; text-align: center;
                margin-bottom: 15px; font-style: italic;
            }
            .main-header {
                background: linear-gradient(135deg, #023e8a 0%, #0077b6 100%);
                padding: 1.5rem 2rem; border-radius: 15px; color: white;
                margin-bottom: 2rem; box-shadow: 0 8px 20px rgba(0, 119, 182, 0.3);
                display: flex; align-items: center; justify-content: space-between;
            }
            .header-left h1 {
                color: #caf0f8 !important; font-weight: 900; margin: 0;
                font-size: 2.2rem; letter-spacing: -0.5px;
            }
            .header-left p {
                color: #e0fbfc; margin: 5px 0 0 0; font-size: 1rem; opacity: 0.9;
            }
            .header-right img {
                border-radius: 50%; border: 3px solid rgba(255,255,255,0.3);
                box-shadow: 0 4px 10px rgba(0,0,0,0.2); width: 100px; height: 100px;
                object-fit: cover;
            }
            [data-testid="stChatMessageContent"] {
                border-radius: 15px !important; padding: 1rem !important;
                box-shadow: 0 2px 4px rgba(0,0,0,0.05);
            }
            [data-testid="stChatMessageContent"]:has(+ [data-testid="stChatMessageAvatar"]) {
                background: #e3f2fd; color: #0d47a1;
            }
            [data-testid="stChatMessageContent"]:not(:has(+ [data-testid="stChatMessageAvatar"])) {
                background: white; border: 1px solid #e9ecef;
                border-left: 5px solid #00b4d8;
            }
            
            /* Style cho ph·∫ßn Ngu·ªìn tham kh·∫£o footer */
            .citation-footer {
                margin-top: 15px;
                padding-top: 10px;
                border-top: 1px dashed #ced4da;
                font-size: 0.85rem;
                color: #495057;
                background-color: #f8f9fa;
                border-radius: 8px;
                padding: 10px;
            }
            .citation-header {
                font-weight: 700;
                color: #d63384; 
                margin-bottom: 5px;
                display: flex;
                align-items: center;
                gap: 5px;
            }
            .citation-item {
                margin-left: 5px;
                margin-bottom: 3px;
                display: block;
            }
            
            div.stButton > button {
                border-radius: 8px; background-color: white; color: #0077b6;
                border: 1px solid #90e0ef; transition: all 0.2s;
            }
            div.stButton > button:hover {
                background-color: #0077b6; color: white;
                border-color: #0077b6; box-shadow: 0 4px 6px rgba(0,0,0,0.1);
            }
            #MainMenu {visibility: hidden;}
            footer {visibility: hidden;}
        </style>
        """, unsafe_allow_html=True)

    @staticmethod
    def render_sidebar():
        with st.sidebar:
            if os.path.exists(AppConfig.LOGO_SCHOOL):
                col1, col2, col3 = st.columns([1, 2, 1])
                with col2:
                    st.image(AppConfig.LOGO_SCHOOL, use_container_width=True)
                st.markdown("<div style='text-align:center; font-weight:700; color:#023e8a; margin-bottom:20px;'>THCS & THPT PH·∫†M KI·ªÜT</div>", unsafe_allow_html=True)

            # Ph·∫ßn th√¥ng tin nh√≥m t√°c gi·∫£ - Gi·ªØ nguy√™n
            st.markdown("""
            <div class="project-card">
                <div class="project-title">KTC CHATBOT</div>
                <div class="project-sub">S·∫£n ph·∫©m d·ª± thi KHKT c·∫•p T·ªânh</div>
                <hr style="margin: 10px 0; border-top: 1px dashed #dee2e6;">
                <div style="font-size: 0.9rem; line-height: 1.6;">
                    <div style="display: flex; justify-content: space-between;">
                        <span style="font-weight: 600; color: #555;">T√°c gi·∫£:</span>
                        <span style="text-align: right; color: #222;"><b>B√πi T√° T√πng</b><br><b>Cao S·ªπ B·∫£o Chung</b></span>
                    </div>
                    <div style="display: flex; justify-content: space-between; margin-top: 8px;">
                        <span style="font-weight: 600; color: #555;">GVHD:</span>
                        <span style="text-align: right; color: #222;">Th·∫ßy <b>Nguy·ªÖn Th·∫ø Khanh</b></span>
                    </div>
                    <div style="display: flex; justify-content: space-between; margin-top: 8px;">
                        <span style="font-weight: 600; color: #555;">NƒÉm h·ªçc:</span>
                        <span style="text-align: right; color: #222;"><b>2025 - 2026</b></span>
                    </div>
                </div>
            </div>
            """, unsafe_allow_html=True)
            
            st.markdown("### ‚öôÔ∏è Ti·ªán √≠ch")
            # N√∫t Re-index d·ªØ li·ªáu (·∫©n trong expander ƒë·ªÉ ƒë·ª° b·∫•m nh·∫ßm)
            with st.expander("Qu·∫£n l√Ω d·ªØ li·ªáu h·ªçc t·∫≠p"):
                uploaded_files = st.file_uploader("N·∫°p th√™m SGK (PDF)", accept_multiple_files=True, type=['pdf'])
                if st.button("üîÑ Hu·∫•n luy·ªán l·∫°i AI (Re-Build DB)", use_container_width=True):
                    if uploaded_files:
                        for up_file in uploaded_files:
                            with open(os.path.join(AppConfig.PDF_DIR, up_file.name), "wb") as f:
                                f.write(up_file.getbuffer())
                    
                    if os.path.exists(AppConfig.VECTOR_DB_PATH):
                        shutil.rmtree(AppConfig.VECTOR_DB_PATH)
                    st.session_state.pop('rag_engine', None)
                    st.rerun()

            if st.button("üóëÔ∏è X√≥a l·ªãch s·ª≠ chat", use_container_width=True):
                st.session_state.messages = []
                st.rerun()

    @staticmethod
    def render_header():
        logo_nhom_b64 = UIManager.get_img_as_base64(AppConfig.LOGO_PROJECT)
        img_html = f'<img src="data:image/jpeg;base64,{logo_nhom_b64}" alt="Logo">' if logo_nhom_b64 else ""

        st.markdown(f"""
        <div class="main-header">
            <div class="header-left">
                <h1>KTC CHATBOT</h1>
                <p style="font-size: 1.1rem; margin-top: 5px;">H·ªçc Tin d·ªÖ d√†ng - Thao t√°c v·ªØng v√†ng</p>
            </div>
            <div class="header-right">
                {img_html}
            </div>
        </div>
        """, unsafe_allow_html=True)

# ==============================================================================
# 3. ADVANCED DATA ENGINEERING - K·ª∏ THU·∫¨T X·ª¨ L√ù D·ªÆ LI·ªÜU C·∫§P QU·ªêC GIA
# ==============================================================================

class KnowledgeBaseBuilder:
    """
    Class ch·ªãu tr√°ch nhi·ªám x·ª≠ l√Ω file PDF th√†nh c√°c chunks th√¥ng minh.
    ƒêi·ªÉm nh·∫•n: Context-Aware Splitting (C·∫Øt theo ng·ªØ c·∫£nh Ch·ªß ƒë·ªÅ/B√†i).
    """

    @staticmethod
    def clean_vietnamese_text(text: str) -> str:
        """L√†m s·∫°ch v√† chu·∫©n h√≥a vƒÉn b·∫£n ti·∫øng Vi·ªát."""
        text = unicodedata.normalize('NFC', text)
        text = re.sub(r'\s+', ' ', text) # X√≥a kho·∫£ng tr·∫Øng th·ª´a
        text = text.replace(' .', '.').replace(' ,', ',')
        return text.strip()

    @staticmethod
    def extract_structure_and_chunk(file_path: str) -> List[Document]:
        """
        [K·ª∏ THU·∫¨T CORE] 
        ƒê·ªçc PDF -> Duy·ªát t·ª´ng d√≤ng -> Ph√°t hi·ªán 'Ch·ªß ƒë·ªÅ'/'B√†i' -> G·∫Øn Metadata.
        """
        filename = os.path.basename(file_path)
        
        # 1. Detect Grade (L·ªõp) from filename (Router data)
        grade = "General"
        if "10" in filename: grade = "10"
        elif "11" in filename: grade = "11"
        elif "12" in filename: grade = "12"

        # 2. Load PDF Text
        loader = PyPDFLoader(file_path)
        pages = loader.load()
        full_text = "\n".join([p.page_content for p in pages])
        full_text = KnowledgeBaseBuilder.clean_vietnamese_text(full_text)
        
        # 3. Define Regex Patterns for Textbook Structure (KNTT)
        # Pattern b·∫Øt: "Ch·ªß ƒë·ªÅ 1: ...", "Ch·ªß ƒë·ªÅ E ...", "CH·ª¶ ƒê·ªÄ F..."
        topic_pattern = re.compile(r'(?:^|\n)(CH·ª¶ ƒê·ªÄ\s+[0-9A-Z]+[.:]?\s+.*)', re.IGNORECASE)
        # Pattern b·∫Øt: "B√†i 1: ...", "B√†i 2 ..."
        lesson_pattern = re.compile(r'(?:^|\n)(B√ÄI\s+[0-9]+[.:]?\s+.*)', re.IGNORECASE)

        lines = full_text.split('.') # T√°ch c√¢u ƒë·ªÉ duy·ªát (ho·∫∑c t√°ch d√≤ng n·∫øu PDF gi·ªØ format t·ªët)
        
        chunks = []
        current_topic = "Ch·ªß ƒë·ªÅ chung"
        current_lesson = "T·ªïng quan"
        buffer_text = ""
        
        # 4. Context-Aware Loop
        # Thay v√¨ c·∫Øt ƒë·ªô d√†i c·ªë ƒë·ªãnh ngay, ta c·∫Øt theo logic b√†i h·ªçc tr∆∞·ªõc
        # Sau ƒë√≥ m·ªõi c·∫Øt nh·ªè theo token n·∫øu b√†i qu√° d√†i.
        
        # ƒê·ªÉ ƒë∆°n gi·∫£n h√≥a cho demo nh∆∞ng v·∫´n hi·ªáu qu·∫£: D√πng RecursiveSplitter nh∆∞ng inject metadata
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=AppConfig.CHUNK_SIZE,
            chunk_overlap=AppConfig.CHUNK_OVERLAP,
            separators=["\n\n", "\n", ". ", " ", ""]
        )
        
        # Duy·ªát t·ª´ng trang ƒë·ªÉ gi·ªØ page number
        for page in pages:
            page_content = KnowledgeBaseBuilder.clean_vietnamese_text(page.page_content)
            
            # Update Context State
            topic_matches = topic_pattern.findall(page_content)
            if topic_matches:
                current_topic = topic_matches[-1].strip() # L·∫•y ch·ªß ƒë·ªÅ m·ªõi nh·∫•t t√¨m th·∫•y
                
            lesson_matches = lesson_pattern.findall(page_content)
            if lesson_matches:
                current_lesson = lesson_matches[-1].strip()
            
            # Create sub-chunks for this page
            page_chunks = text_splitter.create_documents([page_content])
            
            for chunk in page_chunks:
                # [QUAN TR·ªåNG] G·∫Øn Metadata ph√¢n c·∫•p
                chunk.metadata.update({
                    "source": filename,
                    "grade": grade,
                    "topic": current_topic,
                    "lesson": current_lesson,
                    "page": page.metadata.get('page', 0) + 1,
                    # T·∫°o tr∆∞·ªùng citation string ƒë·ªÉ d√πng sau n√†y
                    "citation_label": f"{filename} > {current_topic} > {current_lesson} (Trang {page.metadata.get('page', 0) + 1})"
                })
                chunks.append(chunk)
                
        return chunks

# ==============================================================================
# 4. NATIONAL LEVEL RAG ENGINE - L√ïI X·ª¨ L√ù TH√îNG MINH
# ==============================================================================

class AdvancedRAGEngine:
    def __init__(self, api_key):
        self.groq_client = Groq(api_key=api_key)
        self.embeddings = HuggingFaceEmbeddings(model_name=AppConfig.EMBEDDING_MODEL)
        
        # Load ho·∫∑c Build Vector DB
        self.vector_db = self._initialize_vector_db()
        
        # Kh·ªüi t·∫°o BM25 Retriever (Sparse Search)
        # L∆∞u √Ω: Trong m√¥i tr∆∞·ªùng production, n√™n l∆∞u BM25 ra ƒëƒ©a. ·ªû ƒë√¢y build in-memory cho g·ªçn.
        all_docs = list(self.vector_db.docstore._dict.values())
        self.bm25_retriever = BM25Retriever.from_documents(all_docs)
        self.bm25_retriever.k = AppConfig.RETRIEVAL_K
        
        # Kh·ªüi t·∫°o Reranker
        try:
            self.reranker = Ranker(model_name=AppConfig.RERANK_MODEL_NAME, cache_dir=AppConfig.RERANK_CACHE)
            self.has_reranker = True
        except Exception:
            self.has_reranker = False # Fallback n·∫øu kh√¥ng load ƒë∆∞·ª£c reranker

    def _initialize_vector_db(self):
        """Kh·ªüi t·∫°o FAISS DB. N·∫øu c√≥ r·ªìi th√¨ load, ch∆∞a c√≥ th√¨ build m·ªõi."""
        AppConfig.init_folders()
        
        if os.path.exists(os.path.join(AppConfig.VECTOR_DB_PATH, "index.faiss")):
            try:
                return FAISS.load_local(AppConfig.VECTOR_DB_PATH, self.embeddings, allow_dangerous_deserialization=True)
            except Exception as e:
                st.warning("Index c≈© b·ªã l·ªói, ƒëang t·∫°o m·ªõi...")
        
        # Build new
        pdf_files = glob.glob(os.path.join(AppConfig.PDF_DIR, "*.pdf"))
        if not pdf_files:
            # T·∫°o dummy DB n·∫øu ch∆∞a c√≥ file ƒë·ªÉ tr√°nh crash
            return FAISS.from_texts(["Ch∆∞a c√≥ d·ªØ li·ªáu"], self.embeddings)
            
        all_chunks = []
        progress_bar = st.progress(0, text="ƒêang s·ªë h√≥a tri th·ª©c SGK...")
        
        for i, pdf_path in enumerate(pdf_files):
            chunks = KnowledgeBaseBuilder.extract_structure_and_chunk(pdf_path)
            all_chunks.extend(chunks)
            progress_bar.progress((i + 1) / len(pdf_files))
            
        progress_bar.empty()
        
        if not all_chunks:
            return FAISS.from_texts(["Ch∆∞a c√≥ d·ªØ li·ªáu"], self.embeddings)
            
        db = FAISS.from_documents(all_chunks, self.embeddings)
        db.save_local(AppConfig.VECTOR_DB_PATH)
        return db

    def _detect_intent_and_route(self, query: str) -> Dict:
        """
        [ROUTER] K·ªπ thu·∫≠t ƒë·ªãnh tuy·∫øn c√¢u h·ªèi.
        N·∫øu h·ªèi Tin 10 -> Ch·ªâ t√¨m trong file Tin 10.
        """
        query_lower = query.lower()
        filters = {}
        
        if "tin 10" in query_lower or "l·ªõp 10" in query_lower:
            filters["grade"] = "10"
        elif "tin 11" in query_lower or "l·ªõp 11" in query_lower:
            filters["grade"] = "11"
        elif "tin 12" in query_lower or "l·ªõp 12" in query_lower:
            filters["grade"] = "12"
            
        return filters

    def generate_response(self, user_query: str) -> Generator[str, None, None]:
        """
        Lu·ªìng x·ª≠ l√Ω ch√≠nh: Router -> Hybrid Search -> Rerank -> LLM
        """
        # 1. ROUTING & FILTERING
        metadata_filter = self._detect_intent_and_route(user_query)
        
        # 2. HYBRID RETRIEVAL (Vector + Keyword)
        # Vector Search v·ªõi Filter
        vector_retriever = self.vector_db.as_retriever(
            search_kwargs={"k": AppConfig.RETRIEVAL_K, "filter": metadata_filter} if metadata_filter else {"k": AppConfig.RETRIEVAL_K}
        )
        
        # T·∫°o Ensemble Retriever
        ensemble_retriever = EnsembleRetriever(
            retrievers=[self.bm25_retriever, vector_retriever],
            weights=[AppConfig.BM25_WEIGHT, AppConfig.FAISS_WEIGHT]
        )
        
        try:
            initial_docs = ensemble_retriever.invoke(user_query)
        except Exception:
            # Fallback n·∫øu BM25 l·ªói filter (do BM25 c·ªßa langchain h·∫°n ch·∫ø filter)
            initial_docs = vector_retriever.invoke(user_query)

        if not initial_docs:
            yield "Xin l·ªói, th·∫ßy kh√¥ng t√¨m th·∫•y th√¥ng tin trong SGK."
            return

        # 3. RERANKING (S·∫Øp x·∫øp l·∫°i theo ƒë·ªô ph√π h·ª£p ng·ªØ nghƒ©a s√¢u)
        final_docs = initial_docs
        if self.has_reranker:
            passages = [
                {"id": str(i), "text": doc.page_content, "meta": doc.metadata} 
                for i, doc in enumerate(initial_docs)
            ]
            rerank_request = RerankRequest(query=user_query, passages=passages)
            reranked_results = self.reranker.rank(rerank_request)
            
            # Map l·∫°i k·∫øt qu·∫£ rerank v·ªÅ Document object
            final_docs = []
            for res in reranked_results[:AppConfig.FINAL_K]:
                final_docs.append(Document(page_content=res["text"], metadata=res["meta"]))
        else:
            final_docs = initial_docs[:AppConfig.FINAL_K]

        # 4. CONTEXT CONSTRUCTION
        context_str = ""
        unique_sources = set()
        
        for doc in final_docs:
            context_str += f"N·ªôi dung: {doc.page_content}\n"
            context_str += f"Ngu·ªìn: {doc.metadata.get('citation_label', 'SGK')}\n---\n"
            unique_sources.add(doc.metadata.get('citation_label', 'SGK'))

        # 5. PROMPT ENGINEERING (SYSTEM PROMPT CHU·∫®N S∆Ø PH·∫†M)
        system_prompt = f"""B·∫°n l√† Tr·ª£ l√Ω AI m√¥n Tin h·ªçc c·ªßa tr∆∞·ªùng Ph·∫°m Ki·ªát.
        Nhi·ªám v·ª•: Tr·∫£ l·ªùi c√¢u h·ªèi d·ª±a tr√™n [CONTEXT] b√™n d∆∞·ªõi.
        
        Y√™u c·∫ßu:
        - Tr·∫£ l·ªùi ng·∫Øn g·ªçn, d·ªÖ hi·ªÉu, gi·ªçng vƒÉn th√¢n thi·ªán c·ªßa gi√°o vi√™n.
        - Tuy·ªát ƒë·ªëi trung th·ª±c v·ªõi [CONTEXT]. N·∫øu kh√¥ng c√≥ tin, n√≥i kh√¥ng bi·∫øt.
        - ƒê·ªãnh d·∫°ng Markdown ƒë·∫πp m·∫Øt (d√πng bold, list).
        
        [CONTEXT]:
        {context_str}
        """

        # 6. CALL LLM (STREAMING)
        stream = self.groq_client.chat.completions.create(
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_query}
            ],
            model=AppConfig.LLM_MODEL,
            stream=True,
            temperature=AppConfig.LLM_TEMPERATURE
        )

        full_response = ""
        for chunk in stream:
            if chunk.choices[0].delta.content:
                content = chunk.choices[0].delta.content
                full_response += content
                yield content
        
        # 7. APPEND CITATIONS (T·ª± ƒë·ªông th√™m ngu·ªìn v√†o cu·ªëi c√¢u tr·∫£ l·ªùi)
        yield "\n\n" # Xu·ªëng d√≤ng
        
        # Render HTML Footer cho ngu·ªìn (Hack ƒë·ªÉ hi·ªÉn th·ªã ƒë·∫πp trong Streamlit markdown)
        citation_html = "\n\n<div class='citation-footer'><div class='citation-header'>üìö Ngu·ªìn tham kh·∫£o x√°c th·ª±c:</div>"
        for src in sorted(list(unique_sources)):
            citation_html += f"<span class='citation-item'>‚Ä¢ {src}</span>"
        citation_html += "</div>"
        
        yield citation_html

# ==============================================================================
# 5. MAIN APPLICATION LOGIC
# ==============================================================================

def main():
    if not DEPENDENCIES_OK:
        st.error(f"‚ö†Ô∏è Thi·∫øu th∆∞ vi·ªán: {IMPORT_ERROR}")
        st.stop()

    # Kh·ªüi t·∫°o giao di·ªán
    UIManager.inject_custom_css()
    UIManager.render_sidebar()
    UIManager.render_header()

    # Ki·ªÉm tra API Key
    api_key = st.secrets.get("GROQ_API_KEY")
    if not api_key:
        with st.sidebar:
            api_key = st.text_input("Nh·∫≠p Groq API Key:", type="password")
    
    if not api_key:
        st.warning("Vui l√≤ng nh·∫≠p API Key ƒë·ªÉ b·∫Øt ƒë·∫ßu.")
        return

    # Kh·ªüi t·∫°o RAG Engine (Singleton trong Session State)
    if "rag_engine" not in st.session_state:
        with st.spinner("üöÄ ƒêang kh·ªüi ƒë·ªông h·ªá th·ªëng tri th·ª©c s·ªë..."):
            try:
                st.session_state.rag_engine = AdvancedRAGEngine(api_key)
                st.toast("H·ªá th·ªëng ƒë√£ s·∫µn s√†ng!", icon="‚úÖ")
            except Exception as e:
                st.error(f"L·ªói kh·ªüi t·∫°o: {e}")
                return

    # Qu·∫£n l√Ω l·ªãch s·ª≠ chat
    if "messages" not in st.session_state:
        st.session_state.messages = [{"role": "assistant", "content": "üëã Ch√†o em! Th·∫ßy l√† tr·ª£ l√Ω ·∫£o KTC. Em c·∫ßn t√¨m hi·ªÉu ki·∫øn th·ª©c Tin 10, 11 hay 12?"}]

    # Render tin nh·∫Øn c≈©
    for msg in st.session_state.messages:
        bot_avatar = AppConfig.LOGO_PROJECT if os.path.exists(AppConfig.LOGO_PROJECT) else "ü§ñ"
        avatar = "üßë‚Äçüéì" if msg["role"] == "user" else bot_avatar
        with st.chat_message(msg["role"], avatar=avatar):
            st.markdown(msg["content"], unsafe_allow_html=True) 

    # X·ª≠ l√Ω Input
    user_input = st.chat_input("Nh·∫≠p c√¢u h·ªèi h·ªçc t·∫≠p (V√≠ d·ª•: Tin 10 b√†i c·∫•u tr√∫c r·∫Ω nh√°nh)...")
    
    if user_input:
        # User message
        st.session_state.messages.append({"role": "user", "content": user_input})
        with st.chat_message("user", avatar="üßë‚Äçüéì"):
            st.markdown(user_input)

        # AI Response
        with st.chat_message("assistant", avatar=AppConfig.LOGO_PROJECT if os.path.exists(AppConfig.LOGO_PROJECT) else "ü§ñ"):
            response_placeholder = st.empty()
            full_response = ""
            
            try:
                # G·ªçi Generator
                response_gen = st.session_state.rag_engine.generate_response(user_input)
                
                for chunk in response_gen:
                    full_response += chunk
                    # Update li√™n t·ª•c t·∫°o hi·ªáu ·ª©ng g√µ m√°y
                    response_placeholder.markdown(full_response + "‚ñå", unsafe_allow_html=True)
                
                # Final update (b·ªè con tr·ªè)
                response_placeholder.markdown(full_response, unsafe_allow_html=True)
                
                # L∆∞u v√†o l·ªãch s·ª≠ (bao g·ªìm c·∫£ HTML citation)
                st.session_state.messages.append({"role": "assistant", "content": full_response})
                
            except Exception as e:
                st.error(f"L·ªói: {str(e)}")

if __name__ == "__main__":
    main()