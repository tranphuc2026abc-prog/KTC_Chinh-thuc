import streamlit as st
import os
import glob
import sys

# --- 1. C·∫§U H√åNH TRANG ---
st.set_page_config(
    page_title="Chatbot KTC - Tr·ª£ l√Ω Tin h·ªçc",
    page_icon="ü§ñ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- 2. KI·ªÇM TRA M√îI TR∆Ø·ªúNG (SAFE MODE) ---
try:
    from groq import Groq
    import pdfplumber
    from langchain_text_splitters import RecursiveCharacterTextSplitter
    # THAY ƒê·ªîI QUAN TR·ªåNG: D√πng SKLearn thay v√¨ FAISS
    from langchain_community.vectorstores import SKLearnVectorStore
    from langchain_huggingface import HuggingFaceEmbeddings
    from langchain_core.documents import Document
    LIBRARIES_OK = True
except ImportError as e:
    LIBRARIES_OK = False
    ERROR_DETAIL = str(e)

# --- 3. GIAO DI·ªÜN B√ÅO L·ªñI ---
if not LIBRARIES_OK:
    st.markdown("<h1 style='text-align: center; color: red;'>‚ö†Ô∏è H·ªÜ TH·ªêNG ƒêANG THI·∫æU TH∆Ø VI·ªÜN</h1>", unsafe_allow_html=True)
    st.error(f"L·ªói c·ª• th·ªÉ: {ERROR_DETAIL}")
    st.warning("üëâ Th·∫ßy h√£y ch·∫Øc ch·∫Øn file 'requirements.txt' ƒë√£ c√≥ d√≤ng 'scikit-learn' ch∆∞a nh√©.")
    st.stop()

# --- 4. CODE CH√çNH ---
# --- C√ÅC H·∫∞NG S·ªê ---
MODEL_NAME = 'llama-3.1-8b-instant'
PDF_DIR = "./PDF_KNOWLEDGE"
LOGO_PATH = "LOGO.jpg"
SIMILARITY_THRESHOLD = 1.5 
TOP_K_RETRIEVAL = 6

# --- CSS ---
st.markdown("""
<style>
    .stApp {background-color: #f8f9fa;}
    [data-testid="stSidebar"] {background-color: #ffffff; border-right: 1px solid #e0e0e0;}
    .gradient-text {
        background: linear-gradient(90deg, #0f4c81, #1cb5e0); -webkit-background-clip: text;
        -webkit-text-fill-color: transparent; font-weight: 800; font-size: 2.5rem;
        text-align: center; margin-bottom: 0;
    }
    div[data-testid="stChatMessage"] { background-color: transparent; border: none; padding: 10px; }
    div[data-testid="stChatMessage"][data-testid="user"] { background-color: #e0f2fe; border-radius: 15px 0px 15px 15px; } 
    div[data-testid="stChatMessage"][data-testid="assistant"] { background-color: #ffffff; border: 1px solid #e2e8f0; border-radius: 0px 15px 15px 15px; box-shadow: 0 1px 2px rgba(0,0,0,0.05); }
    .stButton>button { border-radius: 8px; background-color: #0284c7; color: white; border: none; font-weight: 600; }
    .footer-note { text-align: center; font-size: 0.75rem; color: #94a3b8; margin-top: 30px; border-top: 1px dashed #cbd5e1; padding-top: 10px; }
</style>
""", unsafe_allow_html=True)

# --- X·ª¨ L√ù K·∫æT N·ªêI ---
try:
    api_key = st.secrets.get("GROQ_API_KEY", os.getenv("GROQ_API_KEY"))
    if not api_key: raise KeyError("Missing GROQ_API_KEY")
except Exception:
    st.error("‚ùå L·ªói: Ch∆∞a c·∫•u h√¨nh GROQ_API_KEY")
    st.stop()

client = Groq(api_key=api_key)

# --- H√ÄM LOAD DATA ---
@st.cache_resource(show_spinner=False)
def load_data():
    if not os.path.exists(PDF_DIR):
        os.makedirs(PDF_DIR)
        return None
    
    pdf_files = glob.glob(os.path.join(PDF_DIR, "*.pdf"))
    if not pdf_files:
        return None

    documents = []
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)

    # D√πng st.empty ƒë·ªÉ hi·ªán ti·∫øn tr√¨nh m√† kh√¥ng l√†m ch·∫≠m app
    status_text = st.empty()
    status_text.text("ƒêang kh·ªüi ƒë·ªông b·ªô n√£o AI...")
    
    for pdf_path in pdf_files:
        file_name = os.path.basename(pdf_path)
        try:
            with pdfplumber.open(pdf_path) as pdf:
                for i, page in enumerate(pdf.pages):
                    text = page.extract_text()
                    if text:
                        text = text.replace('\n', ' ').strip()
                        chunks = text_splitter.split_text(text)
                        for chunk in chunks:
                            documents.append(Document(page_content=chunk, metadata={"source": file_name, "page": i + 1}))
        except Exception: pass
            
    status_text.empty()
    
    if not documents: return None
    
    embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")
    # S·ª¨ D·ª§NG SKLEARN VECTOR STORE (B·ªÄN B·ªà H∆†N FAISS)
    return SKLearnVectorStore.from_documents(documents=documents, embedding=embeddings)

# --- KH·ªûI T·∫†O STATE ---
if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "assistant", "content": "Ch√†o b·∫°n! Chatbot KTC ƒë√£ s·∫µn s√†ng. H√£y h·ªèi v·ªÅ HTML, AI, Python... nh√©!"}]

if "vector_db" not in st.session_state:
    st.session_state.vector_db = load_data()

# --- SIDEBAR ---
with st.sidebar:
    if os.path.exists(LOGO_PATH):
        st.image(LOGO_PATH, use_container_width=True)
    
    st.markdown("<h3 style='text-align: center; color: #0f4c81;'>TR·ª¢ L√ù KTC</h3>", unsafe_allow_html=True)
    
    # Check n·∫øu vector_db c√≥ d·ªØ li·ªáu (SKLearn store kh√¥ng c√≥ thu·ªôc t√≠nh index.ntotal tr·ª±c ti·∫øp n√™n ta check ki·ªÉu kh√°c)
    if st.session_state.vector_db:
        st.success(f"üü¢ Tr·∫°ng th√°i: ƒê√£ k·∫øt n·ªëi tri th·ª©c")
    else:
        st.error("üî¥ Ch∆∞a c√≥ d·ªØ li·ªáu")

    st.markdown("---")
    
    if st.button("üîÑ N·∫°p l·∫°i d·ªØ li·ªáu g·ªëc", use_container_width=True):
        st.cache_resource.clear()
        st.rerun() 
        
    if st.button("üßπ L√†m m·ªõi h·ªôi tho·∫°i", use_container_width=True):
        st.session_state.messages = []
        st.rerun()

    st.markdown("<div style='margin-top: 20px; font-size: 0.8rem; color: grey'>S·∫£n ph·∫©m KHKT - THCS & THPT Ph·∫°m Ki·ªát</div>", unsafe_allow_html=True)

# --- GIAO DI·ªÜN CH√çNH ---
col1, col2, col3 = st.columns([1, 8, 1])

with col2:
    st.markdown('<h1 class="gradient-text">CHATBOT H·ªñ TR·ª¢ H·ªåC T·∫¨P KTC</h1>', unsafe_allow_html=True)
    st.markdown("<p style='text-align: center; color: #64748b; font-style: italic;'>üöÄ H·ªèi ƒë√°p th√¥ng minh d·ª±a tr√™n t√†i li·ªáu Tin h·ªçc (Anh/Vi·ªát)</p>", unsafe_allow_html=True)
    
    for message in st.session_state.messages:
        avatar = "üßë‚Äçüéì" if message["role"] == "user" else "ü§ñ"
        with st.chat_message(message["role"], avatar=avatar):
            st.markdown(message["content"], unsafe_allow_html=True)

    prompt = st.chat_input("Nh·∫≠p c√¢u h·ªèi c·ªßa b·∫°n t·∫°i ƒë√¢y...")

    if prompt:
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user", avatar="üßë‚Äçüéì"):
            st.markdown(prompt)

        context_text = ""
        relevant_docs = []

        if st.session_state.vector_db:
            # SKLearn tr·∫£ v·ªÅ k·∫øt qu·∫£ t∆∞∆°ng t·ª± FAISS
            results_with_score = st.session_state.vector_db.similarity_search_with_score(prompt, k=TOP_K_RETRIEVAL)
            for doc, score in results_with_score:
                # L∆∞u √Ω: SKLearn score l√† cosine similarity (c√†ng cao c√†ng t·ªët, max l√† 1.0)
                # N√™n ta ph·∫£i ƒë·ªïi logic m·ªôt ch√∫t: L·∫•y nh·ªØng c√°i c√≥ ƒë·ªô t∆∞∆°ng ƒë·ªìng > 0.3 (v√≠ d·ª•)
                # Ho·∫∑c ƒë∆°n gi·∫£n l√† l·∫•y top k·∫øt qu·∫£ t·ªët nh·∫•t
                if score > 0.3: 
                    context_text += f"\n---\n[Ngu·ªìn: {doc.metadata['source']} - Tr.{doc.metadata['page']}]\nN·ªôi dung: {doc.page_content}"
                    relevant_docs.append(doc)
        
        if not context_text:
            system_instruction = """
            B·∫°n l√† Chatbot KTC.
            Hi·ªán t·∫°i b·∫°n KH√îNG t√¨m th·∫•y th√¥ng tin n√†y trong t√†i li·ªáu PDF ƒë∆∞·ª£c cung c·∫•p.
            TUY NHI√äN, h√£y tr·∫£ l·ªùi c√¢u h·ªèi d·ª±a tr√™n ki·∫øn th·ª©c chung c·ªßa b·∫°n v·ªÅ Tin h·ªçc.
            B·∫ÆT BU·ªòC: B·∫Øt ƒë·∫ßu c√¢u tr·∫£ l·ªùi b·∫±ng d√≤ng ch·ªØ in nghi√™ng: *"‚ö†Ô∏è N·ªôi dung n√†y ch∆∞a t√¨m th·∫•y c·ª• th·ªÉ trong t√†i li·ªáu t·∫£i l√™n, ƒë√¢y l√† c√¢u tr·∫£ l·ªùi tham kh·∫£o:"*
            """
        else:
            system_instruction = f"""
            B·∫°n l√† tr·ª£ l√Ω Tin h·ªçc KTC. D·ª±a v√†o B·ªêI C·∫¢NH sau ƒë·ªÉ tr·∫£ l·ªùi h·ªçc sinh.
            B·ªêI C·∫¢NH:
            {context_text}
            
            Y√äU C·∫¶U:
            1. Tr·∫£ l·ªùi ch√≠nh x√°c d·ª±a tr√™n b·ªëi c·∫£nh.
            2. Tr√¨nh b√†y ng·∫Øn g·ªçn, d·ªÖ hi·ªÉu.
            """

        with st.chat_message("assistant", avatar="ü§ñ"):
            placeholder = st.empty()
            full_response = ""
            try:
                chat_completion = client.chat.completions.create(
                    messages=[
                        {"role": "system", "content": system_instruction},
                        {"role": "user", "content": prompt}
                    ],
                    model=MODEL_NAME, stream=True, temperature=0.3
                )
                for chunk in chat_completion:
                    if chunk.choices[0].delta.content:
                        full_response += chunk.choices[0].delta.content
                        placeholder.markdown(full_response + "‚ñå")
                placeholder.markdown(full_response)
                
                if relevant_docs:
                    with st.expander("üìö Minh ch·ª©ng t·ª´ t√†i li·ªáu"):
                        for doc in relevant_docs:
                            st.markdown(f"**üìÑ {doc.metadata['source']} - Trang {doc.metadata['page']}**")
                            st.caption(doc.page_content[:300] + "...") 
                            st.divider()
                
                st.session_state.messages.append({"role": "assistant", "content": full_response})
            except Exception as e:
                st.error(f"L·ªói: {e}")

    st.markdown('<div class="footer-note">‚ö†Ô∏è D·ª± √°n KHKT tr∆∞·ªùng THCS & THPT Ph·∫°m Ki·ªát.</div>', unsafe_allow_html=True)